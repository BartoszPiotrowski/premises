[2018-03-24 16:46:19] Statements of 4564 theorems and definitions loaded.
[2018-03-24 16:46:20] Features of 4564 thms and definitions loaded.
[2018-03-24 16:46:20] Chronological order of 4564 thms and definitions loaded.
[2018-03-24 16:46:20] Creating random rankings of premises for 1342 theorems...
[2018-03-24 16:46:21] Rankings created.
[2018-03-24 16:46:21] ATP evaluation started...
[2018-03-24 17:14:15]     Number of proved theorems: 337
[2018-03-24 17:14:15]     Percentage of proved theorems: 25.11%
[2018-03-24 17:14:15] ITERATION: 0
[2018-03-24 17:14:15] Transforming proofs of 337 theorems to training data...
[2018-03-24 17:14:15]     Number of features used: 5120 / 10241
[2018-03-24 17:14:15]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 17:14:15]     Negatives to positive ratio: 10
[2018-03-24 17:14:15]     No negative mining.
[2018-03-24 17:14:19] Transformation finished.
[2018-03-24 17:14:19] Constructing neural net graph...
[2018-03-24 17:14:20] Training of neural net started...
[2018-03-24 17:14:20] Epoch: 0
[2018-03-24 17:14:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.85/nan/0.00/nan
[2018-03-24 17:14:22] Epoch: 1
[2018-03-24 17:14:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.89/nan/0.00/nan
[2018-03-24 17:14:25] Epoch: 2
[2018-03-24 17:14:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.90/nan/0.00/nan
[2018-03-24 17:14:27] Epoch: 3
[2018-03-24 17:14:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/1.00/0.14/0.25
[2018-03-24 17:14:30] Epoch: 4
[2018-03-24 17:14:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:14:32] Epoch: 5
[2018-03-24 17:14:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.88/1.00/0.08/0.14
[2018-03-24 17:14:35] Epoch: 6
[2018-03-24 17:14:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/0.83/0.42/0.56
[2018-03-24 17:14:37] Epoch: 7
[2018-03-24 17:14:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/0.71/0.45/0.56
[2018-03-24 17:14:40] Epoch: 8
[2018-03-24 17:14:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/1.00/0.11/0.20
[2018-03-24 17:14:42] Epoch: 9
[2018-03-24 17:14:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.90/0.67/0.18/0.29
[2018-03-24 17:14:45] Epoch: 10
[2018-03-24 17:14:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/1.00/0.62/0.76
[2018-03-24 17:14:47] Epoch: 11
[2018-03-24 17:14:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/1.00/0.33/0.50
[2018-03-24 17:14:50] Epoch: 12
[2018-03-24 17:14:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/1.00/0.30/0.46
[2018-03-24 17:14:52] Epoch: 13
[2018-03-24 17:14:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/1.00/0.50/0.67
[2018-03-24 17:14:55] Epoch: 14
[2018-03-24 17:14:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.87/nan/0.00/nan
[2018-03-24 17:14:57] Epoch: 15
[2018-03-24 17:14:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.91/1.00/0.10/0.18
[2018-03-24 17:14:59] Epoch: 16
[2018-03-24 17:15:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/1.00/0.33/0.50
[2018-03-24 17:15:02] Epoch: 17
[2018-03-24 17:15:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/1.00/0.40/0.57
[2018-03-24 17:15:04] Epoch: 18
[2018-03-24 17:15:07] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/1.00/1.00/1.00
[2018-03-24 17:15:07] Epoch: 19
[2018-03-24 17:15:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/0.67/0.29/0.40
[2018-03-24 17:15:09] Epoch: 20
[2018-03-24 17:15:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/1.00/0.50/0.67
[2018-03-24 17:15:12] Epoch: 21
[2018-03-24 17:15:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/0.67/0.22/0.33
[2018-03-24 17:15:14] Epoch: 22
[2018-03-24 17:15:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/1.00/0.67/0.80
[2018-03-24 17:15:16] Epoch: 23
[2018-03-24 17:15:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/1.00/0.43/0.60
[2018-03-24 17:15:19] Epoch: 24
[2018-03-24 17:15:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/1.00/0.57/0.73
[2018-03-24 17:15:21] Epoch: 25
[2018-03-24 17:15:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/1.00/0.60/0.75
[2018-03-24 17:15:24] Epoch: 26
[2018-03-24 17:15:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/1.00/0.22/0.36
[2018-03-24 17:15:26] Epoch: 27
[2018-03-24 17:15:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/1.00/0.17/0.29
[2018-03-24 17:15:29] Epoch: 28
[2018-03-24 17:15:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/1.00/0.33/0.50
[2018-03-24 17:15:31] Epoch: 29
[2018-03-24 17:15:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/1.00/0.50/0.67
[2018-03-24 17:15:34] Epoch: 30
[2018-03-24 17:15:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/1.00/0.89/0.94
[2018-03-24 17:15:36] Epoch: 31
[2018-03-24 17:15:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/1.00/0.44/0.62
[2018-03-24 17:15:38] Epoch: 32
[2018-03-24 17:15:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/1.00/0.17/0.29
[2018-03-24 17:15:41] Epoch: 33
[2018-03-24 17:15:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/0.67/0.67/0.67
[2018-03-24 17:15:43] Epoch: 34
[2018-03-24 17:15:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/1.00/0.92/0.96
[2018-03-24 17:15:46] Epoch: 35
[2018-03-24 17:15:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/1.00/0.50/0.67
[2018-03-24 17:15:48] Epoch: 36
[2018-03-24 17:15:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/1.00/0.62/0.76
[2018-03-24 17:15:50] Epoch: 37
[2018-03-24 17:15:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/1.00/0.45/0.62
[2018-03-24 17:15:53] Epoch: 38
[2018-03-24 17:15:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/0.80/0.67/0.73
[2018-03-24 17:15:55] Epoch: 39
[2018-03-24 17:15:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/1.00/0.56/0.71
[2018-03-24 17:15:58] Epoch: 40
[2018-03-24 17:16:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/0.62/1.00/0.77
[2018-03-24 17:16:00] Epoch: 41
[2018-03-24 17:16:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/1.00/0.50/0.67
[2018-03-24 17:16:03] Epoch: 42
[2018-03-24 17:16:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/1.00/0.75/0.86
[2018-03-24 17:16:05] Epoch: 43
[2018-03-24 17:16:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/0.85/0.85/0.85
[2018-03-24 17:16:08] Epoch: 44
[2018-03-24 17:16:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/1.00/0.50/0.67
[2018-03-24 17:16:10] Epoch: 45
[2018-03-24 17:16:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/1.00/0.58/0.74
[2018-03-24 17:16:12] Epoch: 46
[2018-03-24 17:16:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/1.00/0.57/0.73
[2018-03-24 17:16:15] Epoch: 47
[2018-03-24 17:16:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/1.00/0.67/0.80
[2018-03-24 17:16:17] Epoch: 48
[2018-03-24 17:16:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/0.75/0.75/0.75
[2018-03-24 17:16:20] Epoch: 49
[2018-03-24 17:16:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/0.88/0.70/0.78
[2018-03-24 17:16:22] Training finished.
[2018-03-24 17:16:22] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_171622--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 17:16:23] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 17:17:28] Rankings created.
[2018-03-24 17:17:28] ATP evaluation started...
[2018-03-24 17:37:44]     Number of proved theorems: 579
[2018-03-24 17:37:44]     Percentage of proved theorems: 43.14%
[2018-03-24 17:37:44] Number of all theorems with proof(s): 592
[2018-03-24 17:37:44] Number of all proofs: 1409
[2018-03-24 17:37:44] Number of theorems with exactly 1 proof(s): 242
[2018-03-24 17:37:44] Number of theorems with exactly 2 proof(s): 115
[2018-03-24 17:37:44] Number of theorems with exactly 3 proof(s): 108
[2018-03-24 17:37:44] Number of theorems with exactly 4 proof(s): 60
[2018-03-24 17:37:44] Number of theorems with exactly 5 proof(s): 39
[2018-03-24 17:37:44] Number of theorems with exactly 6 proof(s): 19
[2018-03-24 17:37:44] Number of theorems with exactly 7 proof(s): 8
[2018-03-24 17:37:44] Number of theorems with exactly 8 proof(s): 1
[2018-03-24 17:37:44] Average number of proofs per theorem: 2.380
[2018-03-24 17:37:44] Average number of premises used in one proof: 7.754
[2018-03-24 17:37:44] Theorems with maximal number of proofs found: ['t174_funct_1']
[2018-03-24 17:37:44] ITERATION: 1
[2018-03-24 17:37:44] Transforming proofs of 592 theorems to training data...
[2018-03-24 17:37:44]     Number of features used: 5120 / 10241
[2018-03-24 17:37:44]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 17:37:44]     Negatives to positive ratio: 10
[2018-03-24 17:37:44]     Negative mining:
[2018-03-24 17:37:44]         Level of negative mining: all
[2018-03-24 17:37:44]         Part of theorems for negative mining: 0.5
[2018-03-24 17:41:13] Transformation finished.
[2018-03-24 17:41:13] Restoring neural net graph...
[2018-03-24 17:41:13] Training of neural net started...
[2018-03-24 17:41:13] Epoch: 0
[2018-03-24 17:41:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:41:21] Epoch: 1
[2018-03-24 17:41:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 17:41:29] Epoch: 2
[2018-03-24 17:41:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 17:41:37] Epoch: 3
[2018-03-24 17:41:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 17:41:45] Epoch: 4
[2018-03-24 17:41:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 17:41:52] Epoch: 5
[2018-03-24 17:42:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:42:00] Epoch: 6
[2018-03-24 17:42:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:42:08] Epoch: 7
[2018-03-24 17:42:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:42:16] Epoch: 8
[2018-03-24 17:42:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 17:42:24] Epoch: 9
[2018-03-24 17:42:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:42:32] Epoch: 10
[2018-03-24 17:42:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 17:42:40] Epoch: 11
[2018-03-24 17:42:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 17:42:48] Epoch: 12
[2018-03-24 17:42:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 17:42:56] Epoch: 13
[2018-03-24 17:43:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.78/0.00/0.00/nan
[2018-03-24 17:43:04] Epoch: 14
[2018-03-24 17:43:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 17:43:12] Epoch: 15
[2018-03-24 17:43:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:43:20] Epoch: 16
[2018-03-24 17:43:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:43:28] Epoch: 17
[2018-03-24 17:43:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 17:43:36] Epoch: 18
[2018-03-24 17:43:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 17:43:44] Epoch: 19
[2018-03-24 17:43:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:43:52] Epoch: 20
[2018-03-24 17:44:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:44:00] Epoch: 21
[2018-03-24 17:44:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:44:08] Epoch: 22
[2018-03-24 17:44:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:44:16] Epoch: 23
[2018-03-24 17:44:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:44:24] Epoch: 24
[2018-03-24 17:44:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 17:44:32] Epoch: 25
[2018-03-24 17:44:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:44:40] Epoch: 26
[2018-03-24 17:44:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:44:48] Epoch: 27
[2018-03-24 17:44:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:44:56] Epoch: 28
[2018-03-24 17:45:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:45:04] Epoch: 29
[2018-03-24 17:45:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:45:12] Epoch: 30
[2018-03-24 17:45:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 17:45:20] Epoch: 31
[2018-03-24 17:45:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:45:28] Epoch: 32
[2018-03-24 17:45:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:45:36] Epoch: 33
[2018-03-24 17:45:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 17:45:44] Epoch: 34
[2018-03-24 17:45:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:45:52] Epoch: 35
[2018-03-24 17:46:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:46:00] Epoch: 36
[2018-03-24 17:46:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:46:08] Epoch: 37
[2018-03-24 17:46:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 17:46:16] Epoch: 38
[2018-03-24 17:46:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 17:46:24] Epoch: 39
[2018-03-24 17:46:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:46:32] Epoch: 40
[2018-03-24 17:46:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:46:40] Epoch: 41
[2018-03-24 17:46:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:46:48] Epoch: 42
[2018-03-24 17:46:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:46:56] Epoch: 43
[2018-03-24 17:47:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 17:47:04] Epoch: 44
[2018-03-24 17:47:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:47:12] Epoch: 45
[2018-03-24 17:47:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 17:47:20] Epoch: 46
[2018-03-24 17:47:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 17:47:28] Epoch: 47
[2018-03-24 17:47:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 17:47:36] Epoch: 48
[2018-03-24 17:47:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 17:47:44] Epoch: 49
[2018-03-24 17:47:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 17:47:52] Training finished.
[2018-03-24 17:47:52] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_174752--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 17:47:53] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 17:48:54] Rankings created.
[2018-03-24 17:48:54] ATP evaluation started...
[2018-03-24 18:21:30]     Number of proved theorems: 114
[2018-03-24 18:21:30]     Percentage of proved theorems: 8.49%
[2018-03-24 18:21:30] Number of all theorems with proof(s): 594
[2018-03-24 18:21:30] Number of all proofs: 1502
[2018-03-24 18:21:30] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 18:21:30] Number of theorems with exactly 2 proof(s): 107
[2018-03-24 18:21:30] Number of theorems with exactly 3 proof(s): 99
[2018-03-24 18:21:30] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 18:21:30] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 18:21:30] Number of theorems with exactly 6 proof(s): 21
[2018-03-24 18:21:30] Number of theorems with exactly 7 proof(s): 15
[2018-03-24 18:21:30] Number of theorems with exactly 8 proof(s): 7
[2018-03-24 18:21:30] Average number of proofs per theorem: 2.529
[2018-03-24 18:21:30] Average number of premises used in one proof: 7.707
[2018-03-24 18:21:30] Theorems with maximal number of proofs found: ['t174_funct_1', 't66_xboole_1', 't61_setfam_1', 't84_xboole_1', 't80_xboole_1', 't50_zfmisc_1', 't45_zfmisc_1']
[2018-03-24 18:21:30] ITERATION: 2
[2018-03-24 18:21:30] Transforming proofs of 594 theorems to training data...
[2018-03-24 18:21:30]     Number of features used: 5120 / 10241
[2018-03-24 18:21:30]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 18:21:30]     Negatives to positive ratio: 10
[2018-03-24 18:21:30]     Negative mining:
[2018-03-24 18:21:30]         Level of negative mining: all
[2018-03-24 18:21:30]         Part of theorems for negative mining: 0.5
[2018-03-24 18:24:54] Transformation finished.
[2018-03-24 18:24:54] Restoring neural net graph...
[2018-03-24 18:24:55] Training of neural net started...
[2018-03-24 18:24:55] Epoch: 0
[2018-03-24 18:25:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:25:09] Epoch: 1
[2018-03-24 18:25:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 18:25:22] Epoch: 2
[2018-03-24 18:25:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:25:36] Epoch: 3
[2018-03-24 18:25:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:25:49] Epoch: 4
[2018-03-24 18:26:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:26:02] Epoch: 5
[2018-03-24 18:26:16] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 18:26:16] Epoch: 6
[2018-03-24 18:26:29] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 18:26:29] Epoch: 7
[2018-03-24 18:26:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:26:42] Epoch: 8
[2018-03-24 18:26:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 18:26:56] Epoch: 9
[2018-03-24 18:27:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:27:09] Epoch: 10
[2018-03-24 18:27:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:27:23] Epoch: 11
[2018-03-24 18:27:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:27:36] Epoch: 12
[2018-03-24 18:27:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 18:27:50] Epoch: 13
[2018-03-24 18:28:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:28:03] Epoch: 14
[2018-03-24 18:28:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:28:16] Epoch: 15
[2018-03-24 18:28:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:28:30] Epoch: 16
[2018-03-24 18:28:43] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 18:28:43] Epoch: 17
[2018-03-24 18:28:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:28:56] Epoch: 18
[2018-03-24 18:29:10] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 18:29:10] Epoch: 19
[2018-03-24 18:29:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 18:29:23] Epoch: 20
[2018-03-24 18:29:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:29:36] Epoch: 21
[2018-03-24 18:29:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:29:50] Epoch: 22
[2018-03-24 18:30:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:30:03] Epoch: 23
[2018-03-24 18:30:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 18:30:16] Epoch: 24
[2018-03-24 18:30:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:30:30] Epoch: 25
[2018-03-24 18:30:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:30:43] Epoch: 26
[2018-03-24 18:30:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 18:30:56] Epoch: 27
[2018-03-24 18:31:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 18:31:10] Epoch: 28
[2018-03-24 18:31:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:31:23] Epoch: 29
[2018-03-24 18:31:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 18:31:36] Epoch: 30
[2018-03-24 18:31:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:31:50] Epoch: 31
[2018-03-24 18:32:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:32:03] Epoch: 32
[2018-03-24 18:32:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:32:17] Epoch: 33
[2018-03-24 18:32:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:32:30] Epoch: 34
[2018-03-24 18:32:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:32:44] Epoch: 35
[2018-03-24 18:32:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:32:57] Epoch: 36
[2018-03-24 18:33:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 18:33:11] Epoch: 37
[2018-03-24 18:33:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:33:24] Epoch: 38
[2018-03-24 18:33:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:33:37] Epoch: 39
[2018-03-24 18:33:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:33:51] Epoch: 40
[2018-03-24 18:34:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:34:04] Epoch: 41
[2018-03-24 18:34:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:34:18] Epoch: 42
[2018-03-24 18:34:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 18:34:31] Epoch: 43
[2018-03-24 18:34:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:34:44] Epoch: 44
[2018-03-24 18:34:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 18:34:58] Epoch: 45
[2018-03-24 18:35:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:35:11] Epoch: 46
[2018-03-24 18:35:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:35:24] Epoch: 47
[2018-03-24 18:35:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:35:38] Epoch: 48
[2018-03-24 18:35:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 18:35:51] Epoch: 49
[2018-03-24 18:36:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 18:36:05] Training finished.
[2018-03-24 18:36:05] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_183605--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 18:36:05] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 18:37:08] Rankings created.
[2018-03-24 18:37:08] ATP evaluation started...
[2018-03-24 19:09:46]     Number of proved theorems: 111
[2018-03-24 19:09:46]     Percentage of proved theorems: 8.27%
[2018-03-24 19:09:46] Number of all theorems with proof(s): 594
[2018-03-24 19:09:46] Number of all proofs: 1503
[2018-03-24 19:09:46] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 19:09:46] Number of theorems with exactly 2 proof(s): 107
[2018-03-24 19:09:46] Number of theorems with exactly 3 proof(s): 99
[2018-03-24 19:09:46] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 19:09:46] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 19:09:46] Number of theorems with exactly 6 proof(s): 21
[2018-03-24 19:09:46] Number of theorems with exactly 7 proof(s): 15
[2018-03-24 19:09:46] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 19:09:46] Number of theorems with exactly 9 proof(s): 1
[2018-03-24 19:09:46] Average number of proofs per theorem: 2.530
[2018-03-24 19:09:46] Average number of premises used in one proof: 7.703
[2018-03-24 19:09:46] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 19:09:46] ITERATION: 3
[2018-03-24 19:09:46] Transforming proofs of 594 theorems to training data...
[2018-03-24 19:09:46]     Number of features used: 5120 / 10241
[2018-03-24 19:09:46]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 19:09:46]     Negatives to positive ratio: 10
[2018-03-24 19:09:46]     Negative mining:
[2018-03-24 19:09:46]         Level of negative mining: all
[2018-03-24 19:09:46]         Part of theorems for negative mining: 0.5
[2018-03-24 19:13:13] Transformation finished.
[2018-03-24 19:13:13] Restoring neural net graph...
[2018-03-24 19:13:14] Training of neural net started...
[2018-03-24 19:13:14] Epoch: 0
[2018-03-24 19:13:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:13:28] Epoch: 1
[2018-03-24 19:13:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:13:44] Epoch: 2
[2018-03-24 19:13:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:13:58] Epoch: 3
[2018-03-24 19:14:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:14:14] Epoch: 4
[2018-03-24 19:14:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:14:28] Epoch: 5
[2018-03-24 19:14:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:14:44] Epoch: 6
[2018-03-24 19:14:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:14:59] Epoch: 7
[2018-03-24 19:15:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:15:15] Epoch: 8
[2018-03-24 19:15:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:15:29] Epoch: 9
[2018-03-24 19:15:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:15:45] Epoch: 10
[2018-03-24 19:15:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:15:59] Epoch: 11
[2018-03-24 19:16:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:16:15] Epoch: 12
[2018-03-24 19:16:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 19:16:29] Epoch: 13
[2018-03-24 19:16:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:16:45] Epoch: 14
[2018-03-24 19:16:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:16:59] Epoch: 15
[2018-03-24 19:17:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 19:17:15] Epoch: 16
[2018-03-24 19:17:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:17:29] Epoch: 17
[2018-03-24 19:17:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:17:45] Epoch: 18
[2018-03-24 19:17:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:17:59] Epoch: 19
[2018-03-24 19:18:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:18:15] Epoch: 20
[2018-03-24 19:18:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:18:29] Epoch: 21
[2018-03-24 19:18:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:18:45] Epoch: 22
[2018-03-24 19:18:59] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 19:18:59] Epoch: 23
[2018-03-24 19:19:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:19:15] Epoch: 24
[2018-03-24 19:19:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:19:29] Epoch: 25
[2018-03-24 19:19:45] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 19:19:45] Epoch: 26
[2018-03-24 19:19:59] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 19:19:59] Epoch: 27
[2018-03-24 19:20:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:20:15] Epoch: 28
[2018-03-24 19:20:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:20:29] Epoch: 29
[2018-03-24 19:20:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:20:45] Epoch: 30
[2018-03-24 19:20:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:20:59] Epoch: 31
[2018-03-24 19:21:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:21:15] Epoch: 32
[2018-03-24 19:21:29] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 19:21:29] Epoch: 33
[2018-03-24 19:21:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:21:45] Epoch: 34
[2018-03-24 19:21:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:21:59] Epoch: 35
[2018-03-24 19:22:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:22:15] Epoch: 36
[2018-03-24 19:22:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:22:29] Epoch: 37
[2018-03-24 19:22:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:22:45] Epoch: 38
[2018-03-24 19:22:59] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 19:22:59] Epoch: 39
[2018-03-24 19:23:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 19:23:15] Epoch: 40
[2018-03-24 19:23:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 19:23:29] Epoch: 41
[2018-03-24 19:23:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 19:23:45] Epoch: 42
[2018-03-24 19:23:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:23:59] Epoch: 43
[2018-03-24 19:24:15] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 19:24:15] Epoch: 44
[2018-03-24 19:24:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:24:29] Epoch: 45
[2018-03-24 19:24:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:24:45] Epoch: 46
[2018-03-24 19:24:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:24:59] Epoch: 47
[2018-03-24 19:25:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 19:25:15] Epoch: 48
[2018-03-24 19:25:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 19:25:29] Epoch: 49
[2018-03-24 19:25:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 19:25:45] Training finished.
[2018-03-24 19:25:45] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_192545--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 19:25:46] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 19:26:49] Rankings created.
[2018-03-24 19:26:49] ATP evaluation started...
[2018-03-24 19:59:27]     Number of proved theorems: 111
[2018-03-24 19:59:27]     Percentage of proved theorems: 8.27%
[2018-03-24 19:59:27] Number of all theorems with proof(s): 594
[2018-03-24 19:59:27] Number of all proofs: 1505
[2018-03-24 19:59:27] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 19:59:27] Number of theorems with exactly 2 proof(s): 106
[2018-03-24 19:59:27] Number of theorems with exactly 3 proof(s): 100
[2018-03-24 19:59:27] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 19:59:27] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 19:59:27] Number of theorems with exactly 6 proof(s): 21
[2018-03-24 19:59:27] Number of theorems with exactly 7 proof(s): 15
[2018-03-24 19:59:27] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 19:59:27] Number of theorems with exactly 10 proof(s): 1
[2018-03-24 19:59:27] Average number of proofs per theorem: 2.534
[2018-03-24 19:59:27] Average number of premises used in one proof: 7.707
[2018-03-24 19:59:27] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 19:59:27] ITERATION: 4
[2018-03-24 19:59:27] Transforming proofs of 594 theorems to training data...
[2018-03-24 19:59:27]     Number of features used: 5120 / 10241
[2018-03-24 19:59:27]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 19:59:27]     Negatives to positive ratio: 10
[2018-03-24 19:59:27]     Negative mining:
[2018-03-24 19:59:27]         Level of negative mining: all
[2018-03-24 19:59:27]         Part of theorems for negative mining: 0.5
[2018-03-24 20:02:55] Transformation finished.
[2018-03-24 20:02:55] Restoring neural net graph...
[2018-03-24 20:02:56] Training of neural net started...
[2018-03-24 20:02:56] Epoch: 0
[2018-03-24 20:03:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:03:12] Epoch: 1
[2018-03-24 20:03:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:03:26] Epoch: 2
[2018-03-24 20:03:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:03:42] Epoch: 3
[2018-03-24 20:03:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:03:55] Epoch: 4
[2018-03-24 20:04:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:04:11] Epoch: 5
[2018-03-24 20:04:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:04:25] Epoch: 6
[2018-03-24 20:04:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:04:41] Epoch: 7
[2018-03-24 20:04:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:04:55] Epoch: 8
[2018-03-24 20:05:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:05:11] Epoch: 9
[2018-03-24 20:05:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:05:25] Epoch: 10
[2018-03-24 20:05:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:05:40] Epoch: 11
[2018-03-24 20:05:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:05:54] Epoch: 12
[2018-03-24 20:06:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:06:10] Epoch: 13
[2018-03-24 20:06:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:06:24] Epoch: 14
[2018-03-24 20:06:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 20:06:39] Epoch: 15
[2018-03-24 20:06:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:06:53] Epoch: 16
[2018-03-24 20:07:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:07:09] Epoch: 17
[2018-03-24 20:07:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:07:22] Epoch: 18
[2018-03-24 20:07:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:07:38] Epoch: 19
[2018-03-24 20:07:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:07:52] Epoch: 20
[2018-03-24 20:08:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:08:07] Epoch: 21
[2018-03-24 20:08:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:08:21] Epoch: 22
[2018-03-24 20:08:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:08:37] Epoch: 23
[2018-03-24 20:08:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:08:50] Epoch: 24
[2018-03-24 20:09:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:09:06] Epoch: 25
[2018-03-24 20:09:20] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:09:20] Epoch: 26
[2018-03-24 20:09:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:09:35] Epoch: 27
[2018-03-24 20:09:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:09:49] Epoch: 28
[2018-03-24 20:10:05] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:10:05] Epoch: 29
[2018-03-24 20:10:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:10:19] Epoch: 30
[2018-03-24 20:10:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:10:34] Epoch: 31
[2018-03-24 20:10:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:10:48] Epoch: 32
[2018-03-24 20:11:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:11:04] Epoch: 33
[2018-03-24 20:11:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:11:17] Epoch: 34
[2018-03-24 20:11:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:11:33] Epoch: 35
[2018-03-24 20:11:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:11:47] Epoch: 36
[2018-03-24 20:12:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:12:02] Epoch: 37
[2018-03-24 20:12:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:12:16] Epoch: 38
[2018-03-24 20:12:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:12:32] Epoch: 39
[2018-03-24 20:12:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:12:45] Epoch: 40
[2018-03-24 20:13:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:13:01] Epoch: 41
[2018-03-24 20:13:15] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:13:15] Epoch: 42
[2018-03-24 20:13:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:13:31] Epoch: 43
[2018-03-24 20:13:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:13:44] Epoch: 44
[2018-03-24 20:14:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:14:00] Epoch: 45
[2018-03-24 20:14:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:14:14] Epoch: 46
[2018-03-24 20:14:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:14:29] Epoch: 47
[2018-03-24 20:14:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:14:43] Epoch: 48
[2018-03-24 20:14:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:14:59] Epoch: 49
[2018-03-24 20:15:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:15:12] Training finished.
[2018-03-24 20:15:12] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_201512--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 20:15:13] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 20:16:14] Rankings created.
[2018-03-24 20:16:14] ATP evaluation started...
[2018-03-24 20:48:51]     Number of proved theorems: 112
[2018-03-24 20:48:51]     Percentage of proved theorems: 8.35%
[2018-03-24 20:48:51] Number of all theorems with proof(s): 594
[2018-03-24 20:48:51] Number of all proofs: 1506
[2018-03-24 20:48:51] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 20:48:51] Number of theorems with exactly 2 proof(s): 106
[2018-03-24 20:48:51] Number of theorems with exactly 3 proof(s): 100
[2018-03-24 20:48:51] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 20:48:51] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 20:48:51] Number of theorems with exactly 6 proof(s): 20
[2018-03-24 20:48:51] Number of theorems with exactly 7 proof(s): 16
[2018-03-24 20:48:51] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 20:48:51] Number of theorems with exactly 10 proof(s): 1
[2018-03-24 20:48:51] Average number of proofs per theorem: 2.535
[2018-03-24 20:48:51] Average number of premises used in one proof: 7.701
[2018-03-24 20:48:51] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 20:48:51] ITERATION: 5
[2018-03-24 20:48:51] Transforming proofs of 594 theorems to training data...
[2018-03-24 20:48:51]     Number of features used: 5120 / 10241
[2018-03-24 20:48:51]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 20:48:51]     Negatives to positive ratio: 10
[2018-03-24 20:48:51]     Negative mining:
[2018-03-24 20:48:51]         Level of negative mining: all
[2018-03-24 20:48:51]         Part of theorems for negative mining: 0.5
[2018-03-24 20:52:07] Transformation finished.
[2018-03-24 20:52:07] Restoring neural net graph...
[2018-03-24 20:52:08] Training of neural net started...
[2018-03-24 20:52:08] Epoch: 0
[2018-03-24 20:52:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:52:23] Epoch: 1
[2018-03-24 20:52:37] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:52:37] Epoch: 2
[2018-03-24 20:52:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:52:52] Epoch: 3
[2018-03-24 20:53:05] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:53:05] Epoch: 4
[2018-03-24 20:53:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 20:53:19] Epoch: 5
[2018-03-24 20:53:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:53:33] Epoch: 6
[2018-03-24 20:53:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:53:47] Epoch: 7
[2018-03-24 20:54:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:54:01] Epoch: 8
[2018-03-24 20:54:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:54:15] Epoch: 9
[2018-03-24 20:54:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:54:29] Epoch: 10
[2018-03-24 20:54:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:54:43] Epoch: 11
[2018-03-24 20:54:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:54:57] Epoch: 12
[2018-03-24 20:55:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:55:11] Epoch: 13
[2018-03-24 20:55:25] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:55:25] Epoch: 14
[2018-03-24 20:55:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:55:39] Epoch: 15
[2018-03-24 20:55:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:55:53] Epoch: 16
[2018-03-24 20:56:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:56:07] Epoch: 17
[2018-03-24 20:56:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:56:21] Epoch: 18
[2018-03-24 20:56:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:56:35] Epoch: 19
[2018-03-24 20:56:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:56:49] Epoch: 20
[2018-03-24 20:57:03] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 20:57:03] Epoch: 21
[2018-03-24 20:57:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:57:17] Epoch: 22
[2018-03-24 20:57:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:57:31] Epoch: 23
[2018-03-24 20:57:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:57:45] Epoch: 24
[2018-03-24 20:57:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:57:59] Epoch: 25
[2018-03-24 20:58:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:58:13] Epoch: 26
[2018-03-24 20:58:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:58:27] Epoch: 27
[2018-03-24 20:58:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 20:58:40] Epoch: 28
[2018-03-24 20:58:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:58:55] Epoch: 29
[2018-03-24 20:59:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 20:59:09] Epoch: 30
[2018-03-24 20:59:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 20:59:23] Epoch: 31
[2018-03-24 20:59:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 20:59:37] Epoch: 32
[2018-03-24 20:59:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 20:59:51] Epoch: 33
[2018-03-24 21:00:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:00:05] Epoch: 34
[2018-03-24 21:00:19] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:00:19] Epoch: 35
[2018-03-24 21:00:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:00:33] Epoch: 36
[2018-03-24 21:00:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 21:00:47] Epoch: 37
[2018-03-24 21:01:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:01:01] Epoch: 38
[2018-03-24 21:01:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:01:15] Epoch: 39
[2018-03-24 21:01:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:01:29] Epoch: 40
[2018-03-24 21:01:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:01:44] Epoch: 41
[2018-03-24 21:01:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:01:57] Epoch: 42
[2018-03-24 21:02:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:02:12] Epoch: 43
[2018-03-24 21:02:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:02:26] Epoch: 44
[2018-03-24 21:02:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 21:02:40] Epoch: 45
[2018-03-24 21:02:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:02:54] Epoch: 46
[2018-03-24 21:03:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:03:09] Epoch: 47
[2018-03-24 21:03:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:03:22] Epoch: 48
[2018-03-24 21:03:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:03:37] Epoch: 49
[2018-03-24 21:03:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:03:50] Training finished.
[2018-03-24 21:03:50] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_210350--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 21:03:51] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 21:04:55] Rankings created.
[2018-03-24 21:04:55] ATP evaluation started...
[2018-03-24 21:37:32]     Number of proved theorems: 112
[2018-03-24 21:37:32]     Percentage of proved theorems: 8.35%
[2018-03-24 21:37:32] Number of all theorems with proof(s): 594
[2018-03-24 21:37:32] Number of all proofs: 1506
[2018-03-24 21:37:32] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 21:37:32] Number of theorems with exactly 2 proof(s): 106
[2018-03-24 21:37:32] Number of theorems with exactly 3 proof(s): 100
[2018-03-24 21:37:32] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 21:37:32] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 21:37:32] Number of theorems with exactly 6 proof(s): 20
[2018-03-24 21:37:32] Number of theorems with exactly 7 proof(s): 16
[2018-03-24 21:37:32] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 21:37:32] Number of theorems with exactly 10 proof(s): 1
[2018-03-24 21:37:32] Average number of proofs per theorem: 2.535
[2018-03-24 21:37:32] Average number of premises used in one proof: 7.701
[2018-03-24 21:37:32] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 21:37:32] ITERATION: 6
[2018-03-24 21:37:32] Transforming proofs of 594 theorems to training data...
[2018-03-24 21:37:32]     Number of features used: 5120 / 10241
[2018-03-24 21:37:32]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 21:37:32]     Negatives to positive ratio: 10
[2018-03-24 21:37:32]     Negative mining:
[2018-03-24 21:37:32]         Level of negative mining: all
[2018-03-24 21:37:32]         Part of theorems for negative mining: 0.5
[2018-03-24 21:40:55] Transformation finished.
[2018-03-24 21:40:55] Restoring neural net graph...
[2018-03-24 21:40:56] Training of neural net started...
[2018-03-24 21:40:56] Epoch: 0
[2018-03-24 21:41:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:41:10] Epoch: 1
[2018-03-24 21:41:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:41:24] Epoch: 2
[2018-03-24 21:41:38] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:41:38] Epoch: 3
[2018-03-24 21:41:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:41:52] Epoch: 4
[2018-03-24 21:42:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:42:06] Epoch: 5
[2018-03-24 21:42:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:42:21] Epoch: 6
[2018-03-24 21:42:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 21:42:35] Epoch: 7
[2018-03-24 21:42:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:42:49] Epoch: 8
[2018-03-24 21:43:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:43:03] Epoch: 9
[2018-03-24 21:43:17] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:43:17] Epoch: 10
[2018-03-24 21:43:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:43:31] Epoch: 11
[2018-03-24 21:43:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:43:45] Epoch: 12
[2018-03-24 21:43:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 21:43:59] Epoch: 13
[2018-03-24 21:44:13] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:44:13] Epoch: 14
[2018-03-24 21:44:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:44:27] Epoch: 15
[2018-03-24 21:44:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 21:44:42] Epoch: 16
[2018-03-24 21:44:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:44:56] Epoch: 17
[2018-03-24 21:45:10] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:45:10] Epoch: 18
[2018-03-24 21:45:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:45:24] Epoch: 19
[2018-03-24 21:45:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:45:38] Epoch: 20
[2018-03-24 21:45:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 21:45:52] Epoch: 21
[2018-03-24 21:46:06] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:46:06] Epoch: 22
[2018-03-24 21:46:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:46:20] Epoch: 23
[2018-03-24 21:46:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:46:34] Epoch: 24
[2018-03-24 21:46:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:46:48] Epoch: 25
[2018-03-24 21:47:02] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:47:02] Epoch: 26
[2018-03-24 21:47:17] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:47:17] Epoch: 27
[2018-03-24 21:47:31] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:47:31] Epoch: 28
[2018-03-24 21:47:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 21:47:45] Epoch: 29
[2018-03-24 21:48:00] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:48:00] Epoch: 30
[2018-03-24 21:48:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:48:14] Epoch: 31
[2018-03-24 21:48:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:48:28] Epoch: 32
[2018-03-24 21:48:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:48:42] Epoch: 33
[2018-03-24 21:48:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 21:48:57] Epoch: 34
[2018-03-24 21:49:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 21:49:11] Epoch: 35
[2018-03-24 21:49:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:49:25] Epoch: 36
[2018-03-24 21:49:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:49:40] Epoch: 37
[2018-03-24 21:49:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:49:54] Epoch: 38
[2018-03-24 21:50:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:50:08] Epoch: 39
[2018-03-24 21:50:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 21:50:23] Epoch: 40
[2018-03-24 21:50:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:50:37] Epoch: 41
[2018-03-24 21:50:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:50:51] Epoch: 42
[2018-03-24 21:51:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:51:05] Epoch: 43
[2018-03-24 21:51:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 21:51:20] Epoch: 44
[2018-03-24 21:51:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 21:51:34] Epoch: 45
[2018-03-24 21:51:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 21:51:48] Epoch: 46
[2018-03-24 21:52:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 21:52:02] Epoch: 47
[2018-03-24 21:52:17] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 21:52:17] Epoch: 48
[2018-03-24 21:52:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 21:52:31] Epoch: 49
[2018-03-24 21:52:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 21:52:45] Training finished.
[2018-03-24 21:52:45] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_215245--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 21:52:46] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 21:53:52] Rankings created.
[2018-03-24 21:53:52] ATP evaluation started...
[2018-03-24 22:20:12]     Number of proved theorems: 111
[2018-03-24 22:20:12]     Percentage of proved theorems: 8.27%
[2018-03-24 22:20:12] Number of all theorems with proof(s): 594
[2018-03-24 22:20:12] Number of all proofs: 1506
[2018-03-24 22:20:12] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 22:20:12] Number of theorems with exactly 2 proof(s): 106
[2018-03-24 22:20:12] Number of theorems with exactly 3 proof(s): 100
[2018-03-24 22:20:12] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 22:20:12] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 22:20:12] Number of theorems with exactly 6 proof(s): 20
[2018-03-24 22:20:12] Number of theorems with exactly 7 proof(s): 16
[2018-03-24 22:20:12] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 22:20:12] Number of theorems with exactly 10 proof(s): 1
[2018-03-24 22:20:12] Average number of proofs per theorem: 2.535
[2018-03-24 22:20:13] Average number of premises used in one proof: 7.701
[2018-03-24 22:20:13] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 22:20:13] ITERATION: 7
[2018-03-24 22:20:13] Transforming proofs of 594 theorems to training data...
[2018-03-24 22:20:13]     Number of features used: 5120 / 10241
[2018-03-24 22:20:13]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 22:20:13]     Negatives to positive ratio: 10
[2018-03-24 22:20:13]     Negative mining:
[2018-03-24 22:20:13]         Level of negative mining: all
[2018-03-24 22:20:13]         Part of theorems for negative mining: 0.5
[2018-03-24 22:23:30] Transformation finished.
[2018-03-24 22:23:30] Restoring neural net graph...
[2018-03-24 22:23:31] Training of neural net started...
[2018-03-24 22:23:31] Epoch: 0
[2018-03-24 22:23:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 22:23:45] Epoch: 1
[2018-03-24 22:23:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:23:59] Epoch: 2
[2018-03-24 22:24:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:24:13] Epoch: 3
[2018-03-24 22:24:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:24:26] Epoch: 4
[2018-03-24 22:24:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:24:41] Epoch: 5
[2018-03-24 22:24:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:24:54] Epoch: 6
[2018-03-24 22:25:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:25:08] Epoch: 7
[2018-03-24 22:25:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:25:22] Epoch: 8
[2018-03-24 22:25:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:25:36] Epoch: 9
[2018-03-24 22:25:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:25:49] Epoch: 10
[2018-03-24 22:26:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:26:04] Epoch: 11
[2018-03-24 22:26:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 22:26:17] Epoch: 12
[2018-03-24 22:26:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:26:32] Epoch: 13
[2018-03-24 22:26:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 22:26:45] Epoch: 14
[2018-03-24 22:26:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:26:59] Epoch: 15
[2018-03-24 22:27:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:27:13] Epoch: 16
[2018-03-24 22:27:27] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 22:27:27] Epoch: 17
[2018-03-24 22:27:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:27:40] Epoch: 18
[2018-03-24 22:27:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:27:55] Epoch: 19
[2018-03-24 22:28:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:28:08] Epoch: 20
[2018-03-24 22:28:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:28:23] Epoch: 21
[2018-03-24 22:28:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:28:36] Epoch: 22
[2018-03-24 22:28:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:28:50] Epoch: 23
[2018-03-24 22:29:04] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 22:29:04] Epoch: 24
[2018-03-24 22:29:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:29:19] Epoch: 25
[2018-03-24 22:29:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-24 22:29:32] Epoch: 26
[2018-03-24 22:29:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:29:46] Epoch: 27
[2018-03-24 22:30:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:30:00] Epoch: 28
[2018-03-24 22:30:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:30:14] Epoch: 29
[2018-03-24 22:30:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:30:28] Epoch: 30
[2018-03-24 22:30:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 22:30:42] Epoch: 31
[2018-03-24 22:30:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:30:56] Epoch: 32
[2018-03-24 22:31:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:31:10] Epoch: 33
[2018-03-24 22:31:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:31:23] Epoch: 34
[2018-03-24 22:31:37] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 22:31:37] Epoch: 35
[2018-03-24 22:31:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:31:51] Epoch: 36
[2018-03-24 22:32:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:32:05] Epoch: 37
[2018-03-24 22:32:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:32:19] Epoch: 38
[2018-03-24 22:32:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 22:32:33] Epoch: 39
[2018-03-24 22:32:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:32:46] Epoch: 40
[2018-03-24 22:33:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:33:01] Epoch: 41
[2018-03-24 22:33:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 22:33:14] Epoch: 42
[2018-03-24 22:33:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:33:28] Epoch: 43
[2018-03-24 22:33:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:33:42] Epoch: 44
[2018-03-24 22:33:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:33:56] Epoch: 45
[2018-03-24 22:34:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:34:10] Epoch: 46
[2018-03-24 22:34:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 22:34:24] Epoch: 47
[2018-03-24 22:34:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 22:34:37] Epoch: 48
[2018-03-24 22:34:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 22:34:52] Epoch: 49
[2018-03-24 22:35:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 22:35:05] Training finished.
[2018-03-24 22:35:05] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_223505--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 22:35:06] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 22:36:14] Rankings created.
[2018-03-24 22:36:14] ATP evaluation started...
[2018-03-24 23:02:44]     Number of proved theorems: 112
[2018-03-24 23:02:44]     Percentage of proved theorems: 8.35%
[2018-03-24 23:02:44] Number of all theorems with proof(s): 594
[2018-03-24 23:02:44] Number of all proofs: 1506
[2018-03-24 23:02:44] Number of theorems with exactly 1 proof(s): 239
[2018-03-24 23:02:44] Number of theorems with exactly 2 proof(s): 106
[2018-03-24 23:02:44] Number of theorems with exactly 3 proof(s): 100
[2018-03-24 23:02:44] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 23:02:44] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 23:02:44] Number of theorems with exactly 6 proof(s): 20
[2018-03-24 23:02:44] Number of theorems with exactly 7 proof(s): 16
[2018-03-24 23:02:44] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 23:02:44] Number of theorems with exactly 10 proof(s): 1
[2018-03-24 23:02:44] Average number of proofs per theorem: 2.535
[2018-03-24 23:02:44] Average number of premises used in one proof: 7.701
[2018-03-24 23:02:44] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 23:02:44] ITERATION: 8
[2018-03-24 23:02:44] Transforming proofs of 594 theorems to training data...
[2018-03-24 23:02:44]     Number of features used: 5120 / 10241
[2018-03-24 23:02:44]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 23:02:44]     Negatives to positive ratio: 10
[2018-03-24 23:02:44]     Negative mining:
[2018-03-24 23:02:44]         Level of negative mining: all
[2018-03-24 23:02:44]         Part of theorems for negative mining: 0.5
[2018-03-24 23:06:06] Transformation finished.
[2018-03-24 23:06:06] Restoring neural net graph...
[2018-03-24 23:06:06] Training of neural net started...
[2018-03-24 23:06:06] Epoch: 0
[2018-03-24 23:06:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:06:21] Epoch: 1
[2018-03-24 23:06:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 23:06:36] Epoch: 2
[2018-03-24 23:06:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:06:51] Epoch: 3
[2018-03-24 23:07:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:07:06] Epoch: 4
[2018-03-24 23:07:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:07:19] Epoch: 5
[2018-03-24 23:07:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 23:07:33] Epoch: 6
[2018-03-24 23:07:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:07:47] Epoch: 7
[2018-03-24 23:08:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:08:01] Epoch: 8
[2018-03-24 23:08:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:08:15] Epoch: 9
[2018-03-24 23:08:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:08:28] Epoch: 10
[2018-03-24 23:08:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:08:42] Epoch: 11
[2018-03-24 23:08:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:08:56] Epoch: 12
[2018-03-24 23:09:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:09:10] Epoch: 13
[2018-03-24 23:09:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:09:23] Epoch: 14
[2018-03-24 23:09:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:09:37] Epoch: 15
[2018-03-24 23:09:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:09:51] Epoch: 16
[2018-03-24 23:10:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:10:05] Epoch: 17
[2018-03-24 23:10:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:10:18] Epoch: 18
[2018-03-24 23:10:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:10:32] Epoch: 19
[2018-03-24 23:10:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:10:46] Epoch: 20
[2018-03-24 23:11:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:11:00] Epoch: 21
[2018-03-24 23:11:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:11:13] Epoch: 22
[2018-03-24 23:11:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:11:27] Epoch: 23
[2018-03-24 23:11:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:11:41] Epoch: 24
[2018-03-24 23:11:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:11:55] Epoch: 25
[2018-03-24 23:12:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:12:08] Epoch: 26
[2018-03-24 23:12:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:12:22] Epoch: 27
[2018-03-24 23:12:36] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 23:12:36] Epoch: 28
[2018-03-24 23:12:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:12:49] Epoch: 29
[2018-03-24 23:13:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:13:03] Epoch: 30
[2018-03-24 23:13:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:13:17] Epoch: 31
[2018-03-24 23:13:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:13:31] Epoch: 32
[2018-03-24 23:13:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:13:45] Epoch: 33
[2018-03-24 23:13:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:13:59] Epoch: 34
[2018-03-24 23:14:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:14:13] Epoch: 35
[2018-03-24 23:14:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:14:27] Epoch: 36
[2018-03-24 23:14:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:14:40] Epoch: 37
[2018-03-24 23:14:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:14:54] Epoch: 38
[2018-03-24 23:15:08] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 23:15:08] Epoch: 39
[2018-03-24 23:15:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:15:22] Epoch: 40
[2018-03-24 23:15:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:15:36] Epoch: 41
[2018-03-24 23:15:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:15:49] Epoch: 42
[2018-03-24 23:16:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 23:16:03] Epoch: 43
[2018-03-24 23:16:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:16:17] Epoch: 44
[2018-03-24 23:16:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:16:31] Epoch: 45
[2018-03-24 23:16:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:16:45] Epoch: 46
[2018-03-24 23:16:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:16:59] Epoch: 47
[2018-03-24 23:17:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:17:13] Epoch: 48
[2018-03-24 23:17:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:17:26] Epoch: 49
[2018-03-24 23:17:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:17:40] Training finished.
[2018-03-24 23:17:40] Saving model to file experiments/loop_network_all_h3/model/2018-03-24_231740--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-24 23:17:41] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-24 23:18:42] Rankings created.
[2018-03-24 23:18:42] ATP evaluation started...
[2018-03-24 23:51:19]     Number of proved theorems: 113
[2018-03-24 23:51:19]     Percentage of proved theorems: 8.42%
[2018-03-24 23:51:19] Number of all theorems with proof(s): 594
[2018-03-24 23:51:19] Number of all proofs: 1507
[2018-03-24 23:51:19] Number of theorems with exactly 1 proof(s): 238
[2018-03-24 23:51:19] Number of theorems with exactly 2 proof(s): 107
[2018-03-24 23:51:19] Number of theorems with exactly 3 proof(s): 100
[2018-03-24 23:51:19] Number of theorems with exactly 4 proof(s): 65
[2018-03-24 23:51:19] Number of theorems with exactly 5 proof(s): 41
[2018-03-24 23:51:19] Number of theorems with exactly 6 proof(s): 20
[2018-03-24 23:51:19] Number of theorems with exactly 7 proof(s): 16
[2018-03-24 23:51:19] Number of theorems with exactly 8 proof(s): 6
[2018-03-24 23:51:19] Number of theorems with exactly 10 proof(s): 1
[2018-03-24 23:51:19] Average number of proofs per theorem: 2.537
[2018-03-24 23:51:19] Average number of premises used in one proof: 7.715
[2018-03-24 23:51:19] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-24 23:51:19] ITERATION: 9
[2018-03-24 23:51:19] Transforming proofs of 594 theorems to training data...
[2018-03-24 23:51:19]     Number of features used: 5120 / 10241
[2018-03-24 23:51:19]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-24 23:51:19]     Negatives to positive ratio: 10
[2018-03-24 23:51:19]     Negative mining:
[2018-03-24 23:51:19]         Level of negative mining: all
[2018-03-24 23:51:19]         Part of theorems for negative mining: 0.5
[2018-03-24 23:54:45] Transformation finished.
[2018-03-24 23:54:45] Restoring neural net graph...
[2018-03-24 23:54:46] Training of neural net started...
[2018-03-24 23:54:46] Epoch: 0
[2018-03-24 23:55:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:55:00] Epoch: 1
[2018-03-24 23:55:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:55:13] Epoch: 2
[2018-03-24 23:55:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-24 23:55:27] Epoch: 3
[2018-03-24 23:55:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:55:40] Epoch: 4
[2018-03-24 23:55:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:55:54] Epoch: 5
[2018-03-24 23:56:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:56:07] Epoch: 6
[2018-03-24 23:56:21] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 23:56:21] Epoch: 7
[2018-03-24 23:56:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-24 23:56:34] Epoch: 8
[2018-03-24 23:56:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:56:48] Epoch: 9
[2018-03-24 23:57:01] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-24 23:57:01] Epoch: 10
[2018-03-24 23:57:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:57:15] Epoch: 11
[2018-03-24 23:57:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:57:28] Epoch: 12
[2018-03-24 23:57:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:57:41] Epoch: 13
[2018-03-24 23:57:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-24 23:57:55] Epoch: 14
[2018-03-24 23:58:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:58:08] Epoch: 15
[2018-03-24 23:58:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:58:22] Epoch: 16
[2018-03-24 23:58:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:58:35] Epoch: 17
[2018-03-24 23:58:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-24 23:58:49] Epoch: 18
[2018-03-24 23:59:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-24 23:59:02] Epoch: 19
[2018-03-24 23:59:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:59:16] Epoch: 20
[2018-03-24 23:59:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-24 23:59:29] Epoch: 21
[2018-03-24 23:59:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:59:43] Epoch: 22
[2018-03-24 23:59:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-24 23:59:56] Epoch: 23
[2018-03-25 00:00:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:00:10] Epoch: 24
[2018-03-25 00:00:23] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:00:23] Epoch: 25
[2018-03-25 00:00:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:00:37] Epoch: 26
[2018-03-25 00:00:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:00:50] Epoch: 27
[2018-03-25 00:01:04] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:01:04] Epoch: 28
[2018-03-25 00:01:17] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:01:17] Epoch: 29
[2018-03-25 00:01:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 00:01:31] Epoch: 30
[2018-03-25 00:01:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:01:44] Epoch: 31
[2018-03-25 00:01:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:01:58] Epoch: 32
[2018-03-25 00:02:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:02:12] Epoch: 33
[2018-03-25 00:02:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:02:25] Epoch: 34
[2018-03-25 00:02:39] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:02:39] Epoch: 35
[2018-03-25 00:02:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:02:52] Epoch: 36
[2018-03-25 00:03:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:03:06] Epoch: 37
[2018-03-25 00:03:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:03:20] Epoch: 38
[2018-03-25 00:03:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:03:33] Epoch: 39
[2018-03-25 00:03:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:03:47] Epoch: 40
[2018-03-25 00:04:00] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:04:00] Epoch: 41
[2018-03-25 00:04:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:04:14] Epoch: 42
[2018-03-25 00:04:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:04:27] Epoch: 43
[2018-03-25 00:04:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.91/nan/0.00/nan
[2018-03-25 00:04:41] Epoch: 44
[2018-03-25 00:04:55] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:04:55] Epoch: 45
[2018-03-25 00:05:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:05:08] Epoch: 46
[2018-03-25 00:05:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:05:22] Epoch: 47
[2018-03-25 00:05:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:05:35] Epoch: 48
[2018-03-25 00:05:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:05:49] Epoch: 49
[2018-03-25 00:06:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:06:03] Training finished.
[2018-03-25 00:06:03] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_000603--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 00:06:03] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 00:07:10] Rankings created.
[2018-03-25 00:07:10] ATP evaluation started...
[2018-03-25 00:34:31]     Number of proved theorems: 116
[2018-03-25 00:34:31]     Percentage of proved theorems: 8.64%
[2018-03-25 00:34:31] Number of all theorems with proof(s): 594
[2018-03-25 00:34:31] Number of all proofs: 1511
[2018-03-25 00:34:31] Number of theorems with exactly 1 proof(s): 237
[2018-03-25 00:34:31] Number of theorems with exactly 2 proof(s): 107
[2018-03-25 00:34:31] Number of theorems with exactly 3 proof(s): 101
[2018-03-25 00:34:31] Number of theorems with exactly 4 proof(s): 65
[2018-03-25 00:34:31] Number of theorems with exactly 5 proof(s): 41
[2018-03-25 00:34:31] Number of theorems with exactly 6 proof(s): 20
[2018-03-25 00:34:31] Number of theorems with exactly 7 proof(s): 16
[2018-03-25 00:34:31] Number of theorems with exactly 8 proof(s): 5
[2018-03-25 00:34:31] Number of theorems with exactly 9 proof(s): 1
[2018-03-25 00:34:31] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 00:34:31] Average number of proofs per theorem: 2.544
[2018-03-25 00:34:31] Average number of premises used in one proof: 7.710
[2018-03-25 00:34:31] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 00:34:31] ITERATION: 10
[2018-03-25 00:34:31] Transforming proofs of 594 theorems to training data...
[2018-03-25 00:34:31]     Number of features used: 5120 / 10241
[2018-03-25 00:34:31]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 00:34:31]     Negatives to positive ratio: 10
[2018-03-25 00:34:31]     Negative mining:
[2018-03-25 00:34:31]         Level of negative mining: all
[2018-03-25 00:34:31]         Part of theorems for negative mining: 0.5
[2018-03-25 00:37:53] Transformation finished.
[2018-03-25 00:37:53] Restoring neural net graph...
[2018-03-25 00:37:53] Training of neural net started...
[2018-03-25 00:37:53] Epoch: 0
[2018-03-25 00:38:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:38:07] Epoch: 1
[2018-03-25 00:38:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:38:20] Epoch: 2
[2018-03-25 00:38:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:38:33] Epoch: 3
[2018-03-25 00:38:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:38:46] Epoch: 4
[2018-03-25 00:38:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:38:59] Epoch: 5
[2018-03-25 00:39:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:39:13] Epoch: 6
[2018-03-25 00:39:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:39:26] Epoch: 7
[2018-03-25 00:39:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:39:39] Epoch: 8
[2018-03-25 00:39:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:39:52] Epoch: 9
[2018-03-25 00:40:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:40:05] Epoch: 10
[2018-03-25 00:40:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:40:18] Epoch: 11
[2018-03-25 00:40:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:40:31] Epoch: 12
[2018-03-25 00:40:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 00:40:45] Epoch: 13
[2018-03-25 00:40:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:40:58] Epoch: 14
[2018-03-25 00:41:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:41:11] Epoch: 15
[2018-03-25 00:41:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:41:24] Epoch: 16
[2018-03-25 00:41:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:41:37] Epoch: 17
[2018-03-25 00:41:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:41:50] Epoch: 18
[2018-03-25 00:42:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:42:03] Epoch: 19
[2018-03-25 00:42:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:42:16] Epoch: 20
[2018-03-25 00:42:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:42:30] Epoch: 21
[2018-03-25 00:42:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:42:43] Epoch: 22
[2018-03-25 00:42:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 00:42:56] Epoch: 23
[2018-03-25 00:43:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:43:09] Epoch: 24
[2018-03-25 00:43:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:43:22] Epoch: 25
[2018-03-25 00:43:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:43:35] Epoch: 26
[2018-03-25 00:43:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 00:43:48] Epoch: 27
[2018-03-25 00:44:01] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:44:01] Epoch: 28
[2018-03-25 00:44:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:44:15] Epoch: 29
[2018-03-25 00:44:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 00:44:28] Epoch: 30
[2018-03-25 00:44:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 00:44:41] Epoch: 31
[2018-03-25 00:44:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:44:54] Epoch: 32
[2018-03-25 00:45:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:45:07] Epoch: 33
[2018-03-25 00:45:20] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 00:45:20] Epoch: 34
[2018-03-25 00:45:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:45:33] Epoch: 35
[2018-03-25 00:45:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:45:46] Epoch: 36
[2018-03-25 00:45:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:45:59] Epoch: 37
[2018-03-25 00:46:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:46:13] Epoch: 38
[2018-03-25 00:46:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:46:26] Epoch: 39
[2018-03-25 00:46:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:46:39] Epoch: 40
[2018-03-25 00:46:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 00:46:52] Epoch: 41
[2018-03-25 00:47:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:47:05] Epoch: 42
[2018-03-25 00:47:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 00:47:18] Epoch: 43
[2018-03-25 00:47:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:47:31] Epoch: 44
[2018-03-25 00:47:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:47:44] Epoch: 45
[2018-03-25 00:47:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:47:57] Epoch: 46
[2018-03-25 00:48:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 00:48:10] Epoch: 47
[2018-03-25 00:48:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:48:24] Epoch: 48
[2018-03-25 00:48:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 00:48:37] Epoch: 49
[2018-03-25 00:48:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 00:48:50] Training finished.
[2018-03-25 00:48:50] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_004850--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 00:48:50] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 00:49:53] Rankings created.
[2018-03-25 00:49:53] ATP evaluation started...
[2018-03-25 01:21:20]     Number of proved theorems: 213
[2018-03-25 01:21:20]     Percentage of proved theorems: 15.87%
[2018-03-25 01:21:20] Number of all theorems with proof(s): 615
[2018-03-25 01:21:20] Number of all proofs: 1632
[2018-03-25 01:21:20] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 01:21:20] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 01:21:20] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 01:21:20] Number of theorems with exactly 4 proof(s): 64
[2018-03-25 01:21:20] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 01:21:20] Number of theorems with exactly 6 proof(s): 23
[2018-03-25 01:21:20] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 01:21:20] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 01:21:20] Number of theorems with exactly 9 proof(s): 5
[2018-03-25 01:21:20] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 01:21:20] Average number of proofs per theorem: 2.654
[2018-03-25 01:21:20] Average number of premises used in one proof: 7.567
[2018-03-25 01:21:20] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 01:21:20] ITERATION: 11
[2018-03-25 01:21:20] Transforming proofs of 615 theorems to training data...
[2018-03-25 01:21:20]     Number of features used: 5120 / 10241
[2018-03-25 01:21:20]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 01:21:20]     Negatives to positive ratio: 10
[2018-03-25 01:21:20]     Negative mining:
[2018-03-25 01:21:20]         Level of negative mining: all
[2018-03-25 01:21:20]         Part of theorems for negative mining: 0.5
[2018-03-25 01:24:39] Transformation finished.
[2018-03-25 01:24:39] Restoring neural net graph...
[2018-03-25 01:24:40] Training of neural net started...
[2018-03-25 01:24:40] Epoch: 0
[2018-03-25 01:24:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:24:54] Epoch: 1
[2018-03-25 01:25:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:25:07] Epoch: 2
[2018-03-25 01:25:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:25:20] Epoch: 3
[2018-03-25 01:25:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:25:34] Epoch: 4
[2018-03-25 01:25:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:25:47] Epoch: 5
[2018-03-25 01:26:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:26:01] Epoch: 6
[2018-03-25 01:26:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 01:26:13] Epoch: 7
[2018-03-25 01:26:27] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 01:26:27] Epoch: 8
[2018-03-25 01:26:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:26:40] Epoch: 9
[2018-03-25 01:26:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:26:54] Epoch: 10
[2018-03-25 01:27:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:27:06] Epoch: 11
[2018-03-25 01:27:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:27:20] Epoch: 12
[2018-03-25 01:27:33] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 01:27:33] Epoch: 13
[2018-03-25 01:27:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:27:47] Epoch: 14
[2018-03-25 01:28:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:28:00] Epoch: 15
[2018-03-25 01:28:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 01:28:13] Epoch: 16
[2018-03-25 01:28:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:28:26] Epoch: 17
[2018-03-25 01:28:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:28:40] Epoch: 18
[2018-03-25 01:28:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:28:53] Epoch: 19
[2018-03-25 01:29:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:29:07] Epoch: 20
[2018-03-25 01:29:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 01:29:20] Epoch: 21
[2018-03-25 01:29:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:29:33] Epoch: 22
[2018-03-25 01:29:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 01:29:46] Epoch: 23
[2018-03-25 01:30:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:30:00] Epoch: 24
[2018-03-25 01:30:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:30:12] Epoch: 25
[2018-03-25 01:30:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 01:30:26] Epoch: 26
[2018-03-25 01:30:39] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 01:30:39] Epoch: 27
[2018-03-25 01:30:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:30:52] Epoch: 28
[2018-03-25 01:31:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:31:05] Epoch: 29
[2018-03-25 01:31:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:31:19] Epoch: 30
[2018-03-25 01:31:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:31:31] Epoch: 31
[2018-03-25 01:31:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 01:31:45] Epoch: 32
[2018-03-25 01:31:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:31:58] Epoch: 33
[2018-03-25 01:32:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:32:11] Epoch: 34
[2018-03-25 01:32:24] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 01:32:24] Epoch: 35
[2018-03-25 01:32:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:32:38] Epoch: 36
[2018-03-25 01:32:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:32:50] Epoch: 37
[2018-03-25 01:33:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:33:04] Epoch: 38
[2018-03-25 01:33:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 01:33:17] Epoch: 39
[2018-03-25 01:33:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 01:33:30] Epoch: 40
[2018-03-25 01:33:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:33:43] Epoch: 41
[2018-03-25 01:33:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 01:33:56] Epoch: 42
[2018-03-25 01:34:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 01:34:09] Epoch: 43
[2018-03-25 01:34:23] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 01:34:23] Epoch: 44
[2018-03-25 01:34:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 01:34:36] Epoch: 45
[2018-03-25 01:34:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 01:34:49] Epoch: 46
[2018-03-25 01:35:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 01:35:02] Epoch: 47
[2018-03-25 01:35:15] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 01:35:15] Epoch: 48
[2018-03-25 01:35:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 01:35:28] Epoch: 49
[2018-03-25 01:35:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 01:35:42] Training finished.
[2018-03-25 01:35:42] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_013542--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 01:35:42] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 01:36:48] Rankings created.
[2018-03-25 01:36:48] ATP evaluation started...
[2018-03-25 03:06:19]     Number of proved theorems: 112
[2018-03-25 03:06:19]     Percentage of proved theorems: 8.35%
[2018-03-25 03:06:19] Number of all theorems with proof(s): 615
[2018-03-25 03:06:19] Number of all proofs: 1632
[2018-03-25 03:06:19] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 03:06:19] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 03:06:19] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 03:06:19] Number of theorems with exactly 4 proof(s): 64
[2018-03-25 03:06:19] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 03:06:19] Number of theorems with exactly 6 proof(s): 23
[2018-03-25 03:06:19] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 03:06:19] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 03:06:19] Number of theorems with exactly 9 proof(s): 5
[2018-03-25 03:06:19] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 03:06:19] Average number of proofs per theorem: 2.654
[2018-03-25 03:06:19] Average number of premises used in one proof: 7.567
[2018-03-25 03:06:19] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 03:06:19] ITERATION: 12
[2018-03-25 03:06:19] Transforming proofs of 615 theorems to training data...
[2018-03-25 03:06:19]     Number of features used: 5120 / 10241
[2018-03-25 03:06:19]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 03:06:19]     Negatives to positive ratio: 10
[2018-03-25 03:06:19]     Negative mining:
[2018-03-25 03:06:19]         Level of negative mining: all
[2018-03-25 03:06:19]         Part of theorems for negative mining: 0.5
[2018-03-25 03:09:33] Transformation finished.
[2018-03-25 03:09:33] Restoring neural net graph...
[2018-03-25 03:09:33] Training of neural net started...
[2018-03-25 03:09:33] Epoch: 0
[2018-03-25 03:09:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:09:48] Epoch: 1
[2018-03-25 03:10:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 03:10:04] Epoch: 2
[2018-03-25 03:10:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 03:10:19] Epoch: 3
[2018-03-25 03:10:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:10:35] Epoch: 4
[2018-03-25 03:10:50] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:10:50] Epoch: 5
[2018-03-25 03:11:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 03:11:05] Epoch: 6
[2018-03-25 03:11:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 03:11:21] Epoch: 7
[2018-03-25 03:11:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:11:36] Epoch: 8
[2018-03-25 03:11:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:11:51] Epoch: 9
[2018-03-25 03:12:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:12:07] Epoch: 10
[2018-03-25 03:12:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 03:12:22] Epoch: 11
[2018-03-25 03:12:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 03:12:38] Epoch: 12
[2018-03-25 03:12:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:12:53] Epoch: 13
[2018-03-25 03:13:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 03:13:09] Epoch: 14
[2018-03-25 03:13:24] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:13:24] Epoch: 15
[2018-03-25 03:13:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:13:40] Epoch: 16
[2018-03-25 03:13:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 03:13:54] Epoch: 17
[2018-03-25 03:14:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:14:10] Epoch: 18
[2018-03-25 03:14:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:14:25] Epoch: 19
[2018-03-25 03:14:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:14:41] Epoch: 20
[2018-03-25 03:14:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 03:14:56] Epoch: 21
[2018-03-25 03:15:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:15:11] Epoch: 22
[2018-03-25 03:15:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:15:27] Epoch: 23
[2018-03-25 03:15:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:15:42] Epoch: 24
[2018-03-25 03:15:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:15:57] Epoch: 25
[2018-03-25 03:16:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:16:13] Epoch: 26
[2018-03-25 03:16:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 03:16:28] Epoch: 27
[2018-03-25 03:16:44] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:16:44] Epoch: 28
[2018-03-25 03:16:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:16:59] Epoch: 29
[2018-03-25 03:17:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:17:14] Epoch: 30
[2018-03-25 03:17:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 03:17:30] Epoch: 31
[2018-03-25 03:17:46] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:17:46] Epoch: 32
[2018-03-25 03:18:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:18:00] Epoch: 33
[2018-03-25 03:18:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:18:16] Epoch: 34
[2018-03-25 03:18:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:18:32] Epoch: 35
[2018-03-25 03:18:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:18:48] Epoch: 36
[2018-03-25 03:19:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:19:02] Epoch: 37
[2018-03-25 03:19:18] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:19:18] Epoch: 38
[2018-03-25 03:19:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:19:34] Epoch: 39
[2018-03-25 03:19:49] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:19:49] Epoch: 40
[2018-03-25 03:20:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:20:04] Epoch: 41
[2018-03-25 03:20:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:20:20] Epoch: 42
[2018-03-25 03:20:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:20:36] Epoch: 43
[2018-03-25 03:20:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:20:51] Epoch: 44
[2018-03-25 03:21:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:21:06] Epoch: 45
[2018-03-25 03:21:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:21:22] Epoch: 46
[2018-03-25 03:21:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:21:38] Epoch: 47
[2018-03-25 03:21:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:21:54] Epoch: 48
[2018-03-25 03:22:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:22:09] Epoch: 49
[2018-03-25 03:22:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:22:24] Training finished.
[2018-03-25 03:22:24] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_032224--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 03:22:25] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 03:23:31] Rankings created.
[2018-03-25 03:23:31] ATP evaluation started...
[2018-03-25 03:53:34]     Number of proved theorems: 112
[2018-03-25 03:53:34]     Percentage of proved theorems: 8.35%
[2018-03-25 03:53:34] Number of all theorems with proof(s): 615
[2018-03-25 03:53:34] Number of all proofs: 1635
[2018-03-25 03:53:34] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 03:53:34] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 03:53:34] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 03:53:34] Number of theorems with exactly 4 proof(s): 62
[2018-03-25 03:53:34] Number of theorems with exactly 5 proof(s): 48
[2018-03-25 03:53:34] Number of theorems with exactly 6 proof(s): 23
[2018-03-25 03:53:34] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 03:53:34] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 03:53:34] Number of theorems with exactly 9 proof(s): 4
[2018-03-25 03:53:34] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 03:53:34] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 03:53:34] Average number of proofs per theorem: 2.659
[2018-03-25 03:53:34] Average number of premises used in one proof: 7.568
[2018-03-25 03:53:34] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 03:53:35] ITERATION: 13
[2018-03-25 03:53:35] Transforming proofs of 615 theorems to training data...
[2018-03-25 03:53:35]     Number of features used: 5120 / 10241
[2018-03-25 03:53:35]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 03:53:35]     Negatives to positive ratio: 10
[2018-03-25 03:53:35]     Negative mining:
[2018-03-25 03:53:35]         Level of negative mining: all
[2018-03-25 03:53:35]         Part of theorems for negative mining: 0.5
[2018-03-25 03:56:49] Transformation finished.
[2018-03-25 03:56:49] Restoring neural net graph...
[2018-03-25 03:56:49] Training of neural net started...
[2018-03-25 03:56:49] Epoch: 0
[2018-03-25 03:57:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:57:04] Epoch: 1
[2018-03-25 03:57:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 03:57:18] Epoch: 2
[2018-03-25 03:57:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:57:33] Epoch: 3
[2018-03-25 03:57:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:57:46] Epoch: 4
[2018-03-25 03:58:01] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:58:01] Epoch: 5
[2018-03-25 03:58:14] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 03:58:14] Epoch: 6
[2018-03-25 03:58:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:58:29] Epoch: 7
[2018-03-25 03:58:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:58:42] Epoch: 8
[2018-03-25 03:58:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 03:58:57] Epoch: 9
[2018-03-25 03:59:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:59:10] Epoch: 10
[2018-03-25 03:59:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:59:25] Epoch: 11
[2018-03-25 03:59:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 03:59:38] Epoch: 12
[2018-03-25 03:59:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 03:59:53] Epoch: 13
[2018-03-25 04:00:06] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:00:06] Epoch: 14
[2018-03-25 04:00:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:00:21] Epoch: 15
[2018-03-25 04:00:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:00:35] Epoch: 16
[2018-03-25 04:00:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:00:49] Epoch: 17
[2018-03-25 04:01:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:01:03] Epoch: 18
[2018-03-25 04:01:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:01:17] Epoch: 19
[2018-03-25 04:01:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:01:31] Epoch: 20
[2018-03-25 04:01:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:01:45] Epoch: 21
[2018-03-25 04:01:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:01:59] Epoch: 22
[2018-03-25 04:02:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:02:13] Epoch: 23
[2018-03-25 04:02:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:02:27] Epoch: 24
[2018-03-25 04:02:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:02:41] Epoch: 25
[2018-03-25 04:02:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 04:02:55] Epoch: 26
[2018-03-25 04:03:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:03:10] Epoch: 27
[2018-03-25 04:03:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:03:23] Epoch: 28
[2018-03-25 04:03:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:03:38] Epoch: 29
[2018-03-25 04:03:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:03:51] Epoch: 30
[2018-03-25 04:04:06] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:04:06] Epoch: 31
[2018-03-25 04:04:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:04:19] Epoch: 32
[2018-03-25 04:04:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:04:34] Epoch: 33
[2018-03-25 04:04:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:04:47] Epoch: 34
[2018-03-25 04:05:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 04:05:02] Epoch: 35
[2018-03-25 04:05:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:05:15] Epoch: 36
[2018-03-25 04:05:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-25 04:05:30] Epoch: 37
[2018-03-25 04:05:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:05:43] Epoch: 38
[2018-03-25 04:05:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 04:05:58] Epoch: 39
[2018-03-25 04:06:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:06:11] Epoch: 40
[2018-03-25 04:06:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 04:06:26] Epoch: 41
[2018-03-25 04:06:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:06:39] Epoch: 42
[2018-03-25 04:06:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 04:06:53] Epoch: 43
[2018-03-25 04:07:07] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:07:07] Epoch: 44
[2018-03-25 04:07:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:07:21] Epoch: 45
[2018-03-25 04:07:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:07:35] Epoch: 46
[2018-03-25 04:07:49] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:07:49] Epoch: 47
[2018-03-25 04:08:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:08:03] Epoch: 48
[2018-03-25 04:08:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:08:17] Epoch: 49
[2018-03-25 04:08:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:08:31] Training finished.
[2018-03-25 04:08:31] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_040831--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 04:08:31] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 04:09:38] Rankings created.
[2018-03-25 04:09:38] ATP evaluation started...
[2018-03-25 04:40:18]     Number of proved theorems: 112
[2018-03-25 04:40:18]     Percentage of proved theorems: 8.35%
[2018-03-25 04:40:18] Number of all theorems with proof(s): 615
[2018-03-25 04:40:18] Number of all proofs: 1635
[2018-03-25 04:40:18] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 04:40:18] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 04:40:18] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 04:40:18] Number of theorems with exactly 4 proof(s): 62
[2018-03-25 04:40:18] Number of theorems with exactly 5 proof(s): 48
[2018-03-25 04:40:18] Number of theorems with exactly 6 proof(s): 23
[2018-03-25 04:40:18] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 04:40:18] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 04:40:18] Number of theorems with exactly 9 proof(s): 4
[2018-03-25 04:40:18] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 04:40:18] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 04:40:18] Average number of proofs per theorem: 2.659
[2018-03-25 04:40:18] Average number of premises used in one proof: 7.568
[2018-03-25 04:40:18] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 04:40:18] ITERATION: 14
[2018-03-25 04:40:18] Transforming proofs of 615 theorems to training data...
[2018-03-25 04:40:18]     Number of features used: 5120 / 10241
[2018-03-25 04:40:18]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 04:40:18]     Negatives to positive ratio: 10
[2018-03-25 04:40:18]     Negative mining:
[2018-03-25 04:40:18]         Level of negative mining: all
[2018-03-25 04:40:18]         Part of theorems for negative mining: 0.5
[2018-03-25 04:43:32] Transformation finished.
[2018-03-25 04:43:32] Restoring neural net graph...
[2018-03-25 04:43:33] Training of neural net started...
[2018-03-25 04:43:33] Epoch: 0
[2018-03-25 04:43:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:43:48] Epoch: 1
[2018-03-25 04:44:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:44:02] Epoch: 2
[2018-03-25 04:44:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:44:17] Epoch: 3
[2018-03-25 04:44:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:44:32] Epoch: 4
[2018-03-25 04:44:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:44:46] Epoch: 5
[2018-03-25 04:45:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:45:01] Epoch: 6
[2018-03-25 04:45:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:45:15] Epoch: 7
[2018-03-25 04:45:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:45:30] Epoch: 8
[2018-03-25 04:45:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:45:45] Epoch: 9
[2018-03-25 04:45:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:45:59] Epoch: 10
[2018-03-25 04:46:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:46:14] Epoch: 11
[2018-03-25 04:46:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:46:29] Epoch: 12
[2018-03-25 04:46:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:46:43] Epoch: 13
[2018-03-25 04:46:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:46:58] Epoch: 14
[2018-03-25 04:47:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:47:12] Epoch: 15
[2018-03-25 04:47:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:47:27] Epoch: 16
[2018-03-25 04:47:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:47:41] Epoch: 17
[2018-03-25 04:47:56] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:47:56] Epoch: 18
[2018-03-25 04:48:11] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:48:11] Epoch: 19
[2018-03-25 04:48:25] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:48:25] Epoch: 20
[2018-03-25 04:48:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 04:48:40] Epoch: 21
[2018-03-25 04:48:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:48:54] Epoch: 22
[2018-03-25 04:49:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:49:09] Epoch: 23
[2018-03-25 04:49:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:49:23] Epoch: 24
[2018-03-25 04:49:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:49:38] Epoch: 25
[2018-03-25 04:49:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:49:52] Epoch: 26
[2018-03-25 04:50:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:50:06] Epoch: 27
[2018-03-25 04:50:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 04:50:21] Epoch: 28
[2018-03-25 04:50:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-25 04:50:35] Epoch: 29
[2018-03-25 04:50:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:50:50] Epoch: 30
[2018-03-25 04:51:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:51:04] Epoch: 31
[2018-03-25 04:51:19] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:51:19] Epoch: 32
[2018-03-25 04:51:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:51:33] Epoch: 33
[2018-03-25 04:51:48] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:51:48] Epoch: 34
[2018-03-25 04:52:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:52:02] Epoch: 35
[2018-03-25 04:52:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:52:17] Epoch: 36
[2018-03-25 04:52:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:52:31] Epoch: 37
[2018-03-25 04:52:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:52:46] Epoch: 38
[2018-03-25 04:53:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:53:01] Epoch: 39
[2018-03-25 04:53:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:53:15] Epoch: 40
[2018-03-25 04:53:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 04:53:30] Epoch: 41
[2018-03-25 04:53:44] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:53:44] Epoch: 42
[2018-03-25 04:53:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:53:59] Epoch: 43
[2018-03-25 04:54:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 04:54:13] Epoch: 44
[2018-03-25 04:54:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 04:54:28] Epoch: 45
[2018-03-25 04:54:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:54:42] Epoch: 46
[2018-03-25 04:54:57] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 04:54:57] Epoch: 47
[2018-03-25 04:55:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:55:12] Epoch: 48
[2018-03-25 04:55:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 04:55:26] Epoch: 49
[2018-03-25 04:55:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 04:55:41] Training finished.
[2018-03-25 04:55:41] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_045541--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 04:55:41] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 04:56:47] Rankings created.
[2018-03-25 04:56:47] ATP evaluation started...
[2018-03-25 05:23:07]     Number of proved theorems: 112
[2018-03-25 05:23:07]     Percentage of proved theorems: 8.35%
[2018-03-25 05:23:07] Number of all theorems with proof(s): 615
[2018-03-25 05:23:07] Number of all proofs: 1635
[2018-03-25 05:23:07] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 05:23:07] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 05:23:07] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 05:23:07] Number of theorems with exactly 4 proof(s): 62
[2018-03-25 05:23:07] Number of theorems with exactly 5 proof(s): 48
[2018-03-25 05:23:07] Number of theorems with exactly 6 proof(s): 23
[2018-03-25 05:23:07] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 05:23:07] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 05:23:07] Number of theorems with exactly 9 proof(s): 4
[2018-03-25 05:23:07] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 05:23:07] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 05:23:07] Average number of proofs per theorem: 2.659
[2018-03-25 05:23:07] Average number of premises used in one proof: 7.568
[2018-03-25 05:23:07] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 05:23:07] ITERATION: 15
[2018-03-25 05:23:07] Transforming proofs of 615 theorems to training data...
[2018-03-25 05:23:07]     Number of features used: 5120 / 10241
[2018-03-25 05:23:07]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 05:23:07]     Negatives to positive ratio: 10
[2018-03-25 05:23:07]     Negative mining:
[2018-03-25 05:23:07]         Level of negative mining: all
[2018-03-25 05:23:07]         Part of theorems for negative mining: 0.5
[2018-03-25 05:26:26] Transformation finished.
[2018-03-25 05:26:26] Restoring neural net graph...
[2018-03-25 05:26:26] Training of neural net started...
[2018-03-25 05:26:26] Epoch: 0
[2018-03-25 05:26:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:26:41] Epoch: 1
[2018-03-25 05:26:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:26:56] Epoch: 2
[2018-03-25 05:27:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:27:11] Epoch: 3
[2018-03-25 05:27:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:27:26] Epoch: 4
[2018-03-25 05:27:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:27:41] Epoch: 5
[2018-03-25 05:27:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:27:57] Epoch: 6
[2018-03-25 05:28:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:28:11] Epoch: 7
[2018-03-25 05:28:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:28:27] Epoch: 8
[2018-03-25 05:28:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:28:42] Epoch: 9
[2018-03-25 05:28:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:28:58] Epoch: 10
[2018-03-25 05:29:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:29:12] Epoch: 11
[2018-03-25 05:29:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:29:28] Epoch: 12
[2018-03-25 05:29:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:29:43] Epoch: 13
[2018-03-25 05:29:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:29:59] Epoch: 14
[2018-03-25 05:30:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:30:13] Epoch: 15
[2018-03-25 05:30:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:30:29] Epoch: 16
[2018-03-25 05:30:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:30:44] Epoch: 17
[2018-03-25 05:31:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:31:00] Epoch: 18
[2018-03-25 05:31:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:31:14] Epoch: 19
[2018-03-25 05:31:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:31:30] Epoch: 20
[2018-03-25 05:31:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 05:31:45] Epoch: 21
[2018-03-25 05:32:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:32:01] Epoch: 22
[2018-03-25 05:32:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 05:32:16] Epoch: 23
[2018-03-25 05:32:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:32:31] Epoch: 24
[2018-03-25 05:32:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:32:46] Epoch: 25
[2018-03-25 05:33:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:33:02] Epoch: 26
[2018-03-25 05:33:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:33:17] Epoch: 27
[2018-03-25 05:33:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:33:33] Epoch: 28
[2018-03-25 05:33:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:33:47] Epoch: 29
[2018-03-25 05:34:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:34:03] Epoch: 30
[2018-03-25 05:34:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:34:18] Epoch: 31
[2018-03-25 05:34:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:34:33] Epoch: 32
[2018-03-25 05:34:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:34:48] Epoch: 33
[2018-03-25 05:35:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:35:04] Epoch: 34
[2018-03-25 05:35:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 05:35:19] Epoch: 35
[2018-03-25 05:35:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:35:34] Epoch: 36
[2018-03-25 05:35:49] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 05:35:49] Epoch: 37
[2018-03-25 05:36:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:36:05] Epoch: 38
[2018-03-25 05:36:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:36:20] Epoch: 39
[2018-03-25 05:36:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:36:36] Epoch: 40
[2018-03-25 05:36:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:36:50] Epoch: 41
[2018-03-25 05:37:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:37:06] Epoch: 42
[2018-03-25 05:37:21] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 05:37:21] Epoch: 43
[2018-03-25 05:37:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 05:37:37] Epoch: 44
[2018-03-25 05:37:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 05:37:52] Epoch: 45
[2018-03-25 05:38:08] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 05:38:08] Epoch: 46
[2018-03-25 05:38:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:38:22] Epoch: 47
[2018-03-25 05:38:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:38:38] Epoch: 48
[2018-03-25 05:38:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 05:38:53] Epoch: 49
[2018-03-25 05:39:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 05:39:09] Training finished.
[2018-03-25 05:39:09] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_053909--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 05:39:09] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 05:40:12] Rankings created.
[2018-03-25 05:40:12] ATP evaluation started...
[2018-03-25 06:12:50]     Number of proved theorems: 112
[2018-03-25 06:12:50]     Percentage of proved theorems: 8.35%
[2018-03-25 06:12:50] Number of all theorems with proof(s): 615
[2018-03-25 06:12:50] Number of all proofs: 1635
[2018-03-25 06:12:50] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 06:12:50] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 06:12:50] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 06:12:50] Number of theorems with exactly 4 proof(s): 62
[2018-03-25 06:12:50] Number of theorems with exactly 5 proof(s): 48
[2018-03-25 06:12:50] Number of theorems with exactly 6 proof(s): 23
[2018-03-25 06:12:50] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 06:12:50] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 06:12:50] Number of theorems with exactly 9 proof(s): 4
[2018-03-25 06:12:50] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 06:12:50] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 06:12:50] Average number of proofs per theorem: 2.659
[2018-03-25 06:12:50] Average number of premises used in one proof: 7.568
[2018-03-25 06:12:50] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 06:12:50] ITERATION: 16
[2018-03-25 06:12:50] Transforming proofs of 615 theorems to training data...
[2018-03-25 06:12:50]     Number of features used: 5120 / 10241
[2018-03-25 06:12:50]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 06:12:50]     Negatives to positive ratio: 10
[2018-03-25 06:12:50]     Negative mining:
[2018-03-25 06:12:50]         Level of negative mining: all
[2018-03-25 06:12:50]         Part of theorems for negative mining: 0.5
[2018-03-25 06:15:59] Transformation finished.
[2018-03-25 06:15:59] Restoring neural net graph...
[2018-03-25 06:15:59] Training of neural net started...
[2018-03-25 06:15:59] Epoch: 0
[2018-03-25 06:16:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 06:16:13] Epoch: 1
[2018-03-25 06:16:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:16:26] Epoch: 2
[2018-03-25 06:16:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-25 06:16:40] Epoch: 3
[2018-03-25 06:16:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:16:53] Epoch: 4
[2018-03-25 06:17:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:17:06] Epoch: 5
[2018-03-25 06:17:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:17:19] Epoch: 6
[2018-03-25 06:17:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:17:32] Epoch: 7
[2018-03-25 06:17:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:17:46] Epoch: 8
[2018-03-25 06:17:59] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 06:17:59] Epoch: 9
[2018-03-25 06:18:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:18:12] Epoch: 10
[2018-03-25 06:18:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:18:25] Epoch: 11
[2018-03-25 06:18:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:18:38] Epoch: 12
[2018-03-25 06:18:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:18:51] Epoch: 13
[2018-03-25 06:19:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:19:04] Epoch: 14
[2018-03-25 06:19:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:19:18] Epoch: 15
[2018-03-25 06:19:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:19:31] Epoch: 16
[2018-03-25 06:19:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:19:44] Epoch: 17
[2018-03-25 06:19:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:19:57] Epoch: 18
[2018-03-25 06:20:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:20:10] Epoch: 19
[2018-03-25 06:20:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:20:23] Epoch: 20
[2018-03-25 06:20:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:20:36] Epoch: 21
[2018-03-25 06:20:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:20:49] Epoch: 22
[2018-03-25 06:21:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:21:02] Epoch: 23
[2018-03-25 06:21:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:21:16] Epoch: 24
[2018-03-25 06:21:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:21:29] Epoch: 25
[2018-03-25 06:21:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 06:21:42] Epoch: 26
[2018-03-25 06:21:55] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 06:21:55] Epoch: 27
[2018-03-25 06:22:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:22:08] Epoch: 28
[2018-03-25 06:22:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:22:21] Epoch: 29
[2018-03-25 06:22:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:22:34] Epoch: 30
[2018-03-25 06:22:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:22:47] Epoch: 31
[2018-03-25 06:23:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:23:00] Epoch: 32
[2018-03-25 06:23:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:23:14] Epoch: 33
[2018-03-25 06:23:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:23:27] Epoch: 34
[2018-03-25 06:23:40] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 06:23:40] Epoch: 35
[2018-03-25 06:23:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 06:23:53] Epoch: 36
[2018-03-25 06:24:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:24:06] Epoch: 37
[2018-03-25 06:24:20] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 06:24:20] Epoch: 38
[2018-03-25 06:24:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 06:24:33] Epoch: 39
[2018-03-25 06:24:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:24:46] Epoch: 40
[2018-03-25 06:24:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:24:59] Epoch: 41
[2018-03-25 06:25:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:25:12] Epoch: 42
[2018-03-25 06:25:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-25 06:25:25] Epoch: 43
[2018-03-25 06:25:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:25:39] Epoch: 44
[2018-03-25 06:25:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 06:25:52] Epoch: 45
[2018-03-25 06:26:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 06:26:05] Epoch: 46
[2018-03-25 06:26:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:26:18] Epoch: 47
[2018-03-25 06:26:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 06:26:31] Epoch: 48
[2018-03-25 06:26:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 06:26:44] Epoch: 49
[2018-03-25 06:26:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 06:26:57] Training finished.
[2018-03-25 06:26:57] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_062657--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 06:26:58] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 06:28:05] Rankings created.
[2018-03-25 06:28:05] ATP evaluation started...
[2018-03-25 06:57:32]     Number of proved theorems: 125
[2018-03-25 06:57:32]     Percentage of proved theorems: 9.31%
[2018-03-25 06:57:32] Number of all theorems with proof(s): 616
[2018-03-25 06:57:32] Number of all proofs: 1650
[2018-03-25 06:57:32] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 06:57:32] Number of theorems with exactly 2 proof(s): 102
[2018-03-25 06:57:32] Number of theorems with exactly 3 proof(s): 107
[2018-03-25 06:57:32] Number of theorems with exactly 4 proof(s): 61
[2018-03-25 06:57:32] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 06:57:32] Number of theorems with exactly 6 proof(s): 26
[2018-03-25 06:57:32] Number of theorems with exactly 7 proof(s): 16
[2018-03-25 06:57:32] Number of theorems with exactly 8 proof(s): 8
[2018-03-25 06:57:32] Number of theorems with exactly 9 proof(s): 5
[2018-03-25 06:57:32] Number of theorems with exactly 10 proof(s): 2
[2018-03-25 06:57:32] Number of theorems with exactly 12 proof(s): 1
[2018-03-25 06:57:32] Average number of proofs per theorem: 2.679
[2018-03-25 06:57:32] Average number of premises used in one proof: 7.582
[2018-03-25 06:57:32] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 06:57:33] ITERATION: 17
[2018-03-25 06:57:33] Transforming proofs of 616 theorems to training data...
[2018-03-25 06:57:33]     Number of features used: 5120 / 10241
[2018-03-25 06:57:33]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 06:57:33]     Negatives to positive ratio: 10
[2018-03-25 06:57:33]     Negative mining:
[2018-03-25 06:57:33]         Level of negative mining: all
[2018-03-25 06:57:33]         Part of theorems for negative mining: 0.5
[2018-03-25 07:00:40] Transformation finished.
[2018-03-25 07:00:40] Restoring neural net graph...
[2018-03-25 07:00:40] Training of neural net started...
[2018-03-25 07:00:40] Epoch: 0
[2018-03-25 07:00:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 07:00:54] Epoch: 1
[2018-03-25 07:01:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 07:01:08] Epoch: 2
[2018-03-25 07:01:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:01:22] Epoch: 3
[2018-03-25 07:01:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:01:36] Epoch: 4
[2018-03-25 07:01:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:01:50] Epoch: 5
[2018-03-25 07:02:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:02:03] Epoch: 6
[2018-03-25 07:02:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:02:17] Epoch: 7
[2018-03-25 07:02:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:02:31] Epoch: 8
[2018-03-25 07:02:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 07:02:45] Epoch: 9
[2018-03-25 07:02:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:02:59] Epoch: 10
[2018-03-25 07:03:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:03:12] Epoch: 11
[2018-03-25 07:03:26] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:03:26] Epoch: 12
[2018-03-25 07:03:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:03:40] Epoch: 13
[2018-03-25 07:03:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 07:03:54] Epoch: 14
[2018-03-25 07:04:08] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:04:08] Epoch: 15
[2018-03-25 07:04:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:04:21] Epoch: 16
[2018-03-25 07:04:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:04:35] Epoch: 17
[2018-03-25 07:04:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:04:49] Epoch: 18
[2018-03-25 07:05:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:05:03] Epoch: 19
[2018-03-25 07:05:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:05:17] Epoch: 20
[2018-03-25 07:05:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:05:31] Epoch: 21
[2018-03-25 07:05:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:05:44] Epoch: 22
[2018-03-25 07:05:58] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:05:58] Epoch: 23
[2018-03-25 07:06:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:06:12] Epoch: 24
[2018-03-25 07:06:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:06:26] Epoch: 25
[2018-03-25 07:06:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:06:40] Epoch: 26
[2018-03-25 07:06:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:06:53] Epoch: 27
[2018-03-25 07:07:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:07:07] Epoch: 28
[2018-03-25 07:07:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:07:21] Epoch: 29
[2018-03-25 07:07:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:07:35] Epoch: 30
[2018-03-25 07:07:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:07:49] Epoch: 31
[2018-03-25 07:08:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:08:02] Epoch: 32
[2018-03-25 07:08:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:08:16] Epoch: 33
[2018-03-25 07:08:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:08:30] Epoch: 34
[2018-03-25 07:08:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:08:44] Epoch: 35
[2018-03-25 07:08:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:08:58] Epoch: 36
[2018-03-25 07:09:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:09:12] Epoch: 37
[2018-03-25 07:09:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:09:26] Epoch: 38
[2018-03-25 07:09:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:09:39] Epoch: 39
[2018-03-25 07:09:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:09:53] Epoch: 40
[2018-03-25 07:10:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:10:07] Epoch: 41
[2018-03-25 07:10:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:10:21] Epoch: 42
[2018-03-25 07:10:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:10:35] Epoch: 43
[2018-03-25 07:10:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:10:48] Epoch: 44
[2018-03-25 07:11:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:11:02] Epoch: 45
[2018-03-25 07:11:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:11:16] Epoch: 46
[2018-03-25 07:11:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:11:30] Epoch: 47
[2018-03-25 07:11:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:11:44] Epoch: 48
[2018-03-25 07:11:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:11:57] Epoch: 49
[2018-03-25 07:12:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 07:12:11] Training finished.
[2018-03-25 07:12:11] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_071211--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 07:12:12] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 07:13:13] Rankings created.
[2018-03-25 07:13:13] ATP evaluation started...
[2018-03-25 07:45:45]     Number of proved theorems: 118
[2018-03-25 07:45:45]     Percentage of proved theorems: 8.79%
[2018-03-25 07:45:45] Number of all theorems with proof(s): 616
[2018-03-25 07:45:45] Number of all proofs: 1667
[2018-03-25 07:45:45] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 07:45:45] Number of theorems with exactly 2 proof(s): 103
[2018-03-25 07:45:45] Number of theorems with exactly 3 proof(s): 106
[2018-03-25 07:45:45] Number of theorems with exactly 4 proof(s): 61
[2018-03-25 07:45:45] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 07:45:45] Number of theorems with exactly 6 proof(s): 25
[2018-03-25 07:45:45] Number of theorems with exactly 7 proof(s): 14
[2018-03-25 07:45:45] Number of theorems with exactly 8 proof(s): 11
[2018-03-25 07:45:45] Number of theorems with exactly 9 proof(s): 4
[2018-03-25 07:45:45] Number of theorems with exactly 10 proof(s): 2
[2018-03-25 07:45:45] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 07:45:45] Number of theorems with exactly 12 proof(s): 1
[2018-03-25 07:45:45] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 07:45:45] Average number of proofs per theorem: 2.706
[2018-03-25 07:45:45] Average number of premises used in one proof: 7.585
[2018-03-25 07:45:45] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 07:45:46] ITERATION: 18
[2018-03-25 07:45:46] Transforming proofs of 616 theorems to training data...
[2018-03-25 07:45:46]     Number of features used: 5120 / 10241
[2018-03-25 07:45:46]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 07:45:46]     Negatives to positive ratio: 10
[2018-03-25 07:45:46]     Negative mining:
[2018-03-25 07:45:46]         Level of negative mining: all
[2018-03-25 07:45:46]         Part of theorems for negative mining: 0.5
[2018-03-25 07:48:54] Transformation finished.
[2018-03-25 07:48:54] Restoring neural net graph...
[2018-03-25 07:48:54] Training of neural net started...
[2018-03-25 07:48:54] Epoch: 0
[2018-03-25 07:49:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:49:09] Epoch: 1
[2018-03-25 07:49:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:49:24] Epoch: 2
[2018-03-25 07:49:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:49:39] Epoch: 3
[2018-03-25 07:49:55] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:49:55] Epoch: 4
[2018-03-25 07:50:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:50:10] Epoch: 5
[2018-03-25 07:50:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:50:24] Epoch: 6
[2018-03-25 07:50:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:50:39] Epoch: 7
[2018-03-25 07:50:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 07:50:53] Epoch: 8
[2018-03-25 07:51:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:51:09] Epoch: 9
[2018-03-25 07:51:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:51:23] Epoch: 10
[2018-03-25 07:51:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:51:38] Epoch: 11
[2018-03-25 07:51:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:51:52] Epoch: 12
[2018-03-25 07:52:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:52:08] Epoch: 13
[2018-03-25 07:52:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:52:22] Epoch: 14
[2018-03-25 07:52:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:52:37] Epoch: 15
[2018-03-25 07:52:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:52:51] Epoch: 16
[2018-03-25 07:53:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:53:07] Epoch: 17
[2018-03-25 07:53:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:53:21] Epoch: 18
[2018-03-25 07:53:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:53:36] Epoch: 19
[2018-03-25 07:53:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:53:50] Epoch: 20
[2018-03-25 07:54:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:54:06] Epoch: 21
[2018-03-25 07:54:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 07:54:20] Epoch: 22
[2018-03-25 07:54:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:54:35] Epoch: 23
[2018-03-25 07:54:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:54:49] Epoch: 24
[2018-03-25 07:55:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:55:04] Epoch: 25
[2018-03-25 07:55:19] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:55:19] Epoch: 26
[2018-03-25 07:55:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 07:55:34] Epoch: 27
[2018-03-25 07:55:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:55:48] Epoch: 28
[2018-03-25 07:56:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 07:56:04] Epoch: 29
[2018-03-25 07:56:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:56:18] Epoch: 30
[2018-03-25 07:56:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:56:33] Epoch: 31
[2018-03-25 07:56:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:56:48] Epoch: 32
[2018-03-25 07:57:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:57:03] Epoch: 33
[2018-03-25 07:57:17] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:57:17] Epoch: 34
[2018-03-25 07:57:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:57:33] Epoch: 35
[2018-03-25 07:57:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:57:47] Epoch: 36
[2018-03-25 07:58:02] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 07:58:02] Epoch: 37
[2018-03-25 07:58:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:58:16] Epoch: 38
[2018-03-25 07:58:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 07:58:31] Epoch: 39
[2018-03-25 07:58:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 07:58:46] Epoch: 40
[2018-03-25 07:59:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 07:59:01] Epoch: 41
[2018-03-25 07:59:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 07:59:15] Epoch: 42
[2018-03-25 07:59:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:59:30] Epoch: 43
[2018-03-25 07:59:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:59:44] Epoch: 44
[2018-03-25 07:59:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 07:59:59] Epoch: 45
[2018-03-25 08:00:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:00:13] Epoch: 46
[2018-03-25 08:00:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 08:00:28] Epoch: 47
[2018-03-25 08:00:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:00:42] Epoch: 48
[2018-03-25 08:00:57] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:00:57] Epoch: 49
[2018-03-25 08:01:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:01:11] Training finished.
[2018-03-25 08:01:11] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_080111--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 08:01:12] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 08:02:14] Rankings created.
[2018-03-25 08:02:14] ATP evaluation started...
[2018-03-25 08:34:51]     Number of proved theorems: 113
[2018-03-25 08:34:51]     Percentage of proved theorems: 8.42%
[2018-03-25 08:34:51] Number of all theorems with proof(s): 616
[2018-03-25 08:34:51] Number of all proofs: 1668
[2018-03-25 08:34:51] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 08:34:51] Number of theorems with exactly 2 proof(s): 103
[2018-03-25 08:34:51] Number of theorems with exactly 3 proof(s): 106
[2018-03-25 08:34:51] Number of theorems with exactly 4 proof(s): 61
[2018-03-25 08:34:51] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 08:34:51] Number of theorems with exactly 6 proof(s): 24
[2018-03-25 08:34:51] Number of theorems with exactly 7 proof(s): 15
[2018-03-25 08:34:51] Number of theorems with exactly 8 proof(s): 11
[2018-03-25 08:34:51] Number of theorems with exactly 9 proof(s): 4
[2018-03-25 08:34:51] Number of theorems with exactly 10 proof(s): 2
[2018-03-25 08:34:51] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 08:34:51] Number of theorems with exactly 12 proof(s): 1
[2018-03-25 08:34:51] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 08:34:51] Average number of proofs per theorem: 2.708
[2018-03-25 08:34:51] Average number of premises used in one proof: 7.587
[2018-03-25 08:34:51] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 08:34:51] ITERATION: 19
[2018-03-25 08:34:51] Transforming proofs of 616 theorems to training data...
[2018-03-25 08:34:51]     Number of features used: 5120 / 10241
[2018-03-25 08:34:51]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 08:34:51]     Negatives to positive ratio: 10
[2018-03-25 08:34:51]     Negative mining:
[2018-03-25 08:34:51]         Level of negative mining: all
[2018-03-25 08:34:51]         Part of theorems for negative mining: 0.5
[2018-03-25 08:38:08] Transformation finished.
[2018-03-25 08:38:08] Restoring neural net graph...
[2018-03-25 08:38:08] Training of neural net started...
[2018-03-25 08:38:08] Epoch: 0
[2018-03-25 08:38:23] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:38:23] Epoch: 1
[2018-03-25 08:38:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:38:38] Epoch: 2
[2018-03-25 08:38:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:38:53] Epoch: 3
[2018-03-25 08:39:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:39:08] Epoch: 4
[2018-03-25 08:39:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:39:22] Epoch: 5
[2018-03-25 08:39:37] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:39:37] Epoch: 6
[2018-03-25 08:39:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:39:51] Epoch: 7
[2018-03-25 08:40:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:40:06] Epoch: 8
[2018-03-25 08:40:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:40:21] Epoch: 9
[2018-03-25 08:40:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:40:36] Epoch: 10
[2018-03-25 08:40:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 08:40:51] Epoch: 11
[2018-03-25 08:41:05] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:41:05] Epoch: 12
[2018-03-25 08:41:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:41:20] Epoch: 13
[2018-03-25 08:41:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 08:41:35] Epoch: 14
[2018-03-25 08:41:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 08:41:50] Epoch: 15
[2018-03-25 08:42:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 08:42:04] Epoch: 16
[2018-03-25 08:42:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 08:42:19] Epoch: 17
[2018-03-25 08:42:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:42:34] Epoch: 18
[2018-03-25 08:42:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:42:49] Epoch: 19
[2018-03-25 08:43:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:43:04] Epoch: 20
[2018-03-25 08:43:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 08:43:18] Epoch: 21
[2018-03-25 08:43:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:43:33] Epoch: 22
[2018-03-25 08:43:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:43:48] Epoch: 23
[2018-03-25 08:44:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:44:03] Epoch: 24
[2018-03-25 08:44:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 08:44:18] Epoch: 25
[2018-03-25 08:44:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:44:33] Epoch: 26
[2018-03-25 08:44:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:44:48] Epoch: 27
[2018-03-25 08:45:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 08:45:03] Epoch: 28
[2018-03-25 08:45:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:45:18] Epoch: 29
[2018-03-25 08:45:33] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:45:33] Epoch: 30
[2018-03-25 08:45:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:45:48] Epoch: 31
[2018-03-25 08:46:03] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:46:03] Epoch: 32
[2018-03-25 08:46:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:46:17] Epoch: 33
[2018-03-25 08:46:32] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 08:46:32] Epoch: 34
[2018-03-25 08:46:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:46:47] Epoch: 35
[2018-03-25 08:47:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 08:47:02] Epoch: 36
[2018-03-25 08:47:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:47:17] Epoch: 37
[2018-03-25 08:47:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:47:32] Epoch: 38
[2018-03-25 08:47:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:47:47] Epoch: 39
[2018-03-25 08:48:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:48:02] Epoch: 40
[2018-03-25 08:48:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 08:48:17] Epoch: 41
[2018-03-25 08:48:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:48:32] Epoch: 42
[2018-03-25 08:48:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 08:48:47] Epoch: 43
[2018-03-25 08:49:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:49:02] Epoch: 44
[2018-03-25 08:49:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 08:49:16] Epoch: 45
[2018-03-25 08:49:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:49:31] Epoch: 46
[2018-03-25 08:49:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 08:49:46] Epoch: 47
[2018-03-25 08:50:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 08:50:01] Epoch: 48
[2018-03-25 08:50:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 08:50:16] Epoch: 49
[2018-03-25 08:50:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-25 08:50:32] Training finished.
[2018-03-25 08:50:32] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_085032--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 08:50:32] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 08:51:37] Rankings created.
[2018-03-25 08:51:37] ATP evaluation started...
[2018-03-25 09:21:29]     Number of proved theorems: 144
[2018-03-25 09:21:29]     Percentage of proved theorems: 10.73%
[2018-03-25 09:21:29] Number of all theorems with proof(s): 618
[2018-03-25 09:21:29] Number of all proofs: 1707
[2018-03-25 09:21:29] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 09:21:29] Number of theorems with exactly 2 proof(s): 99
[2018-03-25 09:21:29] Number of theorems with exactly 3 proof(s): 103
[2018-03-25 09:21:29] Number of theorems with exactly 4 proof(s): 64
[2018-03-25 09:21:29] Number of theorems with exactly 5 proof(s): 44
[2018-03-25 09:21:29] Number of theorems with exactly 6 proof(s): 30
[2018-03-25 09:21:29] Number of theorems with exactly 7 proof(s): 13
[2018-03-25 09:21:29] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 09:21:29] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 09:21:29] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 09:21:29] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 09:21:29] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 09:21:29] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 09:21:29] Average number of proofs per theorem: 2.762
[2018-03-25 09:21:29] Average number of premises used in one proof: 7.680
[2018-03-25 09:21:29] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 09:21:29] ITERATION: 20
[2018-03-25 09:21:29] Transforming proofs of 618 theorems to training data...
[2018-03-25 09:21:29]     Number of features used: 5120 / 10241
[2018-03-25 09:21:29]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 09:21:29]     Negatives to positive ratio: 10
[2018-03-25 09:21:29]     Negative mining:
[2018-03-25 09:21:29]         Level of negative mining: all
[2018-03-25 09:21:29]         Part of theorems for negative mining: 0.5
[2018-03-25 09:24:43] Transformation finished.
[2018-03-25 09:24:43] Restoring neural net graph...
[2018-03-25 09:24:43] Training of neural net started...
[2018-03-25 09:24:43] Epoch: 0
[2018-03-25 09:24:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 09:24:58] Epoch: 1
[2018-03-25 09:25:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:25:12] Epoch: 2
[2018-03-25 09:25:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 09:25:27] Epoch: 3
[2018-03-25 09:25:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 09:25:41] Epoch: 4
[2018-03-25 09:25:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:25:55] Epoch: 5
[2018-03-25 09:26:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 09:26:09] Epoch: 6
[2018-03-25 09:26:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.93/nan/0.00/nan
[2018-03-25 09:26:23] Epoch: 7
[2018-03-25 09:26:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:26:37] Epoch: 8
[2018-03-25 09:26:51] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 09:26:51] Epoch: 9
[2018-03-25 09:27:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:27:06] Epoch: 10
[2018-03-25 09:27:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:27:20] Epoch: 11
[2018-03-25 09:27:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:27:34] Epoch: 12
[2018-03-25 09:27:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 09:27:48] Epoch: 13
[2018-03-25 09:28:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 09:28:02] Epoch: 14
[2018-03-25 09:28:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 09:28:16] Epoch: 15
[2018-03-25 09:28:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:28:30] Epoch: 16
[2018-03-25 09:28:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:28:44] Epoch: 17
[2018-03-25 09:28:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 09:28:58] Epoch: 18
[2018-03-25 09:29:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 09:29:13] Epoch: 19
[2018-03-25 09:29:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 09:29:27] Epoch: 20
[2018-03-25 09:29:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:29:41] Epoch: 21
[2018-03-25 09:29:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:29:55] Epoch: 22
[2018-03-25 09:30:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:30:09] Epoch: 23
[2018-03-25 09:30:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:30:23] Epoch: 24
[2018-03-25 09:30:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 09:30:37] Epoch: 25
[2018-03-25 09:30:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:30:51] Epoch: 26
[2018-03-25 09:31:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:31:06] Epoch: 27
[2018-03-25 09:31:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:31:20] Epoch: 28
[2018-03-25 09:31:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 09:31:34] Epoch: 29
[2018-03-25 09:31:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 09:31:48] Epoch: 30
[2018-03-25 09:32:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:32:02] Epoch: 31
[2018-03-25 09:32:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:32:16] Epoch: 32
[2018-03-25 09:32:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 09:32:31] Epoch: 33
[2018-03-25 09:32:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:32:45] Epoch: 34
[2018-03-25 09:32:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:32:59] Epoch: 35
[2018-03-25 09:33:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 09:33:13] Epoch: 36
[2018-03-25 09:33:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:33:27] Epoch: 37
[2018-03-25 09:33:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:33:41] Epoch: 38
[2018-03-25 09:33:56] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 09:33:56] Epoch: 39
[2018-03-25 09:34:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 09:34:10] Epoch: 40
[2018-03-25 09:34:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:34:24] Epoch: 41
[2018-03-25 09:34:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 09:34:38] Epoch: 42
[2018-03-25 09:34:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 09:34:53] Epoch: 43
[2018-03-25 09:35:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-25 09:35:07] Epoch: 44
[2018-03-25 09:35:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:35:21] Epoch: 45
[2018-03-25 09:35:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:35:35] Epoch: 46
[2018-03-25 09:35:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 09:35:49] Epoch: 47
[2018-03-25 09:36:04] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 09:36:04] Epoch: 48
[2018-03-25 09:36:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:36:18] Epoch: 49
[2018-03-25 09:36:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 09:36:32] Training finished.
[2018-03-25 09:36:32] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_093632--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 09:36:33] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 09:37:38] Rankings created.
[2018-03-25 09:37:38] ATP evaluation started...
[2018-03-25 10:04:08]     Number of proved theorems: 112
[2018-03-25 10:04:08]     Percentage of proved theorems: 8.35%
[2018-03-25 10:04:08] Number of all theorems with proof(s): 618
[2018-03-25 10:04:08] Number of all proofs: 1707
[2018-03-25 10:04:08] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 10:04:08] Number of theorems with exactly 2 proof(s): 99
[2018-03-25 10:04:08] Number of theorems with exactly 3 proof(s): 103
[2018-03-25 10:04:08] Number of theorems with exactly 4 proof(s): 64
[2018-03-25 10:04:08] Number of theorems with exactly 5 proof(s): 44
[2018-03-25 10:04:08] Number of theorems with exactly 6 proof(s): 30
[2018-03-25 10:04:08] Number of theorems with exactly 7 proof(s): 13
[2018-03-25 10:04:08] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 10:04:08] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 10:04:08] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 10:04:08] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 10:04:08] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 10:04:08] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 10:04:08] Average number of proofs per theorem: 2.762
[2018-03-25 10:04:08] Average number of premises used in one proof: 7.680
[2018-03-25 10:04:08] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 10:04:08] ITERATION: 21
[2018-03-25 10:04:08] Transforming proofs of 618 theorems to training data...
[2018-03-25 10:04:08]     Number of features used: 5120 / 10241
[2018-03-25 10:04:08]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 10:04:08]     Negatives to positive ratio: 10
[2018-03-25 10:04:08]     Negative mining:
[2018-03-25 10:04:08]         Level of negative mining: all
[2018-03-25 10:04:08]         Part of theorems for negative mining: 0.5
[2018-03-25 10:07:16] Transformation finished.
[2018-03-25 10:07:16] Restoring neural net graph...
[2018-03-25 10:07:16] Training of neural net started...
[2018-03-25 10:07:16] Epoch: 0
[2018-03-25 10:07:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:07:31] Epoch: 1
[2018-03-25 10:07:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:07:46] Epoch: 2
[2018-03-25 10:08:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:08:01] Epoch: 3
[2018-03-25 10:08:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:08:15] Epoch: 4
[2018-03-25 10:08:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:08:30] Epoch: 5
[2018-03-25 10:08:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 10:08:44] Epoch: 6
[2018-03-25 10:08:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 10:08:59] Epoch: 7
[2018-03-25 10:09:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:09:13] Epoch: 8
[2018-03-25 10:09:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:09:28] Epoch: 9
[2018-03-25 10:09:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:09:42] Epoch: 10
[2018-03-25 10:09:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:09:57] Epoch: 11
[2018-03-25 10:10:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:10:11] Epoch: 12
[2018-03-25 10:10:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 10:10:26] Epoch: 13
[2018-03-25 10:10:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:10:41] Epoch: 14
[2018-03-25 10:10:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:10:56] Epoch: 15
[2018-03-25 10:11:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:11:10] Epoch: 16
[2018-03-25 10:11:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:11:25] Epoch: 17
[2018-03-25 10:11:39] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:11:39] Epoch: 18
[2018-03-25 10:11:54] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:11:54] Epoch: 19
[2018-03-25 10:12:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:12:08] Epoch: 20
[2018-03-25 10:12:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:12:23] Epoch: 21
[2018-03-25 10:12:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 10:12:37] Epoch: 22
[2018-03-25 10:12:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 10:12:52] Epoch: 23
[2018-03-25 10:13:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:13:07] Epoch: 24
[2018-03-25 10:13:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:13:22] Epoch: 25
[2018-03-25 10:13:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:13:36] Epoch: 26
[2018-03-25 10:13:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:13:51] Epoch: 27
[2018-03-25 10:14:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:14:05] Epoch: 28
[2018-03-25 10:14:20] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:14:20] Epoch: 29
[2018-03-25 10:14:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:14:34] Epoch: 30
[2018-03-25 10:14:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:14:49] Epoch: 31
[2018-03-25 10:15:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:15:03] Epoch: 32
[2018-03-25 10:15:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:15:18] Epoch: 33
[2018-03-25 10:15:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:15:32] Epoch: 34
[2018-03-25 10:15:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:15:47] Epoch: 35
[2018-03-25 10:16:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:16:02] Epoch: 36
[2018-03-25 10:16:16] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:16:16] Epoch: 37
[2018-03-25 10:16:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:16:31] Epoch: 38
[2018-03-25 10:16:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:16:46] Epoch: 39
[2018-03-25 10:17:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:17:00] Epoch: 40
[2018-03-25 10:17:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:17:15] Epoch: 41
[2018-03-25 10:17:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 10:17:29] Epoch: 42
[2018-03-25 10:17:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 10:17:44] Epoch: 43
[2018-03-25 10:17:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:17:59] Epoch: 44
[2018-03-25 10:18:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:18:14] Epoch: 45
[2018-03-25 10:18:28] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:18:28] Epoch: 46
[2018-03-25 10:18:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:18:43] Epoch: 47
[2018-03-25 10:18:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:18:57] Epoch: 48
[2018-03-25 10:19:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:19:13] Epoch: 49
[2018-03-25 10:19:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:19:27] Training finished.
[2018-03-25 10:19:27] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_101927--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 10:19:27] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 10:20:33] Rankings created.
[2018-03-25 10:20:33] ATP evaluation started...
[2018-03-25 10:49:25]     Number of proved theorems: 137
[2018-03-25 10:49:25]     Percentage of proved theorems: 10.21%
[2018-03-25 10:49:25] Number of all theorems with proof(s): 618
[2018-03-25 10:49:25] Number of all proofs: 1719
[2018-03-25 10:49:25] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 10:49:25] Number of theorems with exactly 2 proof(s): 98
[2018-03-25 10:49:25] Number of theorems with exactly 3 proof(s): 103
[2018-03-25 10:49:25] Number of theorems with exactly 4 proof(s): 65
[2018-03-25 10:49:25] Number of theorems with exactly 5 proof(s): 44
[2018-03-25 10:49:25] Number of theorems with exactly 6 proof(s): 31
[2018-03-25 10:49:25] Number of theorems with exactly 7 proof(s): 13
[2018-03-25 10:49:25] Number of theorems with exactly 8 proof(s): 9
[2018-03-25 10:49:25] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 10:49:25] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 10:49:25] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 10:49:25] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 10:49:25] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 10:49:25] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 10:49:25] Average number of proofs per theorem: 2.782
[2018-03-25 10:49:25] Average number of premises used in one proof: 7.714
[2018-03-25 10:49:25] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 10:49:25] ITERATION: 22
[2018-03-25 10:49:25] Transforming proofs of 618 theorems to training data...
[2018-03-25 10:49:25]     Number of features used: 5120 / 10241
[2018-03-25 10:49:25]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 10:49:25]     Negatives to positive ratio: 10
[2018-03-25 10:49:25]     Negative mining:
[2018-03-25 10:49:25]         Level of negative mining: all
[2018-03-25 10:49:25]         Part of theorems for negative mining: 0.5
[2018-03-25 10:52:45] Transformation finished.
[2018-03-25 10:52:45] Restoring neural net graph...
[2018-03-25 10:52:45] Training of neural net started...
[2018-03-25 10:52:45] Epoch: 0
[2018-03-25 10:52:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:52:59] Epoch: 1
[2018-03-25 10:53:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:53:13] Epoch: 2
[2018-03-25 10:53:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:53:27] Epoch: 3
[2018-03-25 10:53:40] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:53:40] Epoch: 4
[2018-03-25 10:53:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 10:53:54] Epoch: 5
[2018-03-25 10:54:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:54:08] Epoch: 6
[2018-03-25 10:54:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:54:22] Epoch: 7
[2018-03-25 10:54:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:54:36] Epoch: 8
[2018-03-25 10:54:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:54:50] Epoch: 9
[2018-03-25 10:55:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:55:03] Epoch: 10
[2018-03-25 10:55:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:55:17] Epoch: 11
[2018-03-25 10:55:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:55:31] Epoch: 12
[2018-03-25 10:55:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 10:55:44] Epoch: 13
[2018-03-25 10:55:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:55:58] Epoch: 14
[2018-03-25 10:56:12] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:56:12] Epoch: 15
[2018-03-25 10:56:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 10:56:25] Epoch: 16
[2018-03-25 10:56:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:56:39] Epoch: 17
[2018-03-25 10:56:53] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:56:53] Epoch: 18
[2018-03-25 10:57:07] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:57:07] Epoch: 19
[2018-03-25 10:57:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:57:20] Epoch: 20
[2018-03-25 10:57:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:57:34] Epoch: 21
[2018-03-25 10:57:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:57:48] Epoch: 22
[2018-03-25 10:58:01] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:58:01] Epoch: 23
[2018-03-25 10:58:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:58:15] Epoch: 24
[2018-03-25 10:58:29] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 10:58:29] Epoch: 25
[2018-03-25 10:58:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 10:58:42] Epoch: 26
[2018-03-25 10:58:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:58:56] Epoch: 27
[2018-03-25 10:59:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:59:09] Epoch: 28
[2018-03-25 10:59:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 10:59:23] Epoch: 29
[2018-03-25 10:59:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 10:59:36] Epoch: 30
[2018-03-25 10:59:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 10:59:50] Epoch: 31
[2018-03-25 11:00:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:00:04] Epoch: 32
[2018-03-25 11:00:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:00:17] Epoch: 33
[2018-03-25 11:00:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:00:31] Epoch: 34
[2018-03-25 11:00:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:00:44] Epoch: 35
[2018-03-25 11:00:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 11:00:58] Epoch: 36
[2018-03-25 11:01:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:01:11] Epoch: 37
[2018-03-25 11:01:24] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 11:01:24] Epoch: 38
[2018-03-25 11:01:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 11:01:38] Epoch: 39
[2018-03-25 11:01:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:01:51] Epoch: 40
[2018-03-25 11:02:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:02:05] Epoch: 41
[2018-03-25 11:02:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:02:18] Epoch: 42
[2018-03-25 11:02:32] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 11:02:32] Epoch: 43
[2018-03-25 11:02:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:02:45] Epoch: 44
[2018-03-25 11:02:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:02:59] Epoch: 45
[2018-03-25 11:03:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:03:12] Epoch: 46
[2018-03-25 11:03:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 11:03:25] Epoch: 47
[2018-03-25 11:03:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:03:39] Epoch: 48
[2018-03-25 11:03:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 11:03:52] Epoch: 49
[2018-03-25 11:04:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:04:06] Training finished.
[2018-03-25 11:04:06] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_110406--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 11:04:06] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 11:05:12] Rankings created.
[2018-03-25 11:05:12] ATP evaluation started...
[2018-03-25 11:34:05]     Number of proved theorems: 111
[2018-03-25 11:34:05]     Percentage of proved theorems: 8.27%
[2018-03-25 11:34:05] Number of all theorems with proof(s): 618
[2018-03-25 11:34:05] Number of all proofs: 1719
[2018-03-25 11:34:05] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 11:34:05] Number of theorems with exactly 2 proof(s): 98
[2018-03-25 11:34:05] Number of theorems with exactly 3 proof(s): 103
[2018-03-25 11:34:05] Number of theorems with exactly 4 proof(s): 65
[2018-03-25 11:34:05] Number of theorems with exactly 5 proof(s): 44
[2018-03-25 11:34:05] Number of theorems with exactly 6 proof(s): 31
[2018-03-25 11:34:05] Number of theorems with exactly 7 proof(s): 13
[2018-03-25 11:34:05] Number of theorems with exactly 8 proof(s): 9
[2018-03-25 11:34:05] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 11:34:05] Number of theorems with exactly 10 proof(s): 1
[2018-03-25 11:34:05] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 11:34:05] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 11:34:05] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 11:34:05] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 11:34:05] Average number of proofs per theorem: 2.782
[2018-03-25 11:34:05] Average number of premises used in one proof: 7.714
[2018-03-25 11:34:05] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 11:34:05] ITERATION: 23
[2018-03-25 11:34:05] Transforming proofs of 618 theorems to training data...
[2018-03-25 11:34:05]     Number of features used: 5120 / 10241
[2018-03-25 11:34:05]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 11:34:05]     Negatives to positive ratio: 10
[2018-03-25 11:34:05]     Negative mining:
[2018-03-25 11:34:05]         Level of negative mining: all
[2018-03-25 11:34:05]         Part of theorems for negative mining: 0.5
[2018-03-25 11:37:27] Transformation finished.
[2018-03-25 11:37:27] Restoring neural net graph...
[2018-03-25 11:37:28] Training of neural net started...
[2018-03-25 11:37:28] Epoch: 0
[2018-03-25 11:37:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:37:43] Epoch: 1
[2018-03-25 11:37:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:37:57] Epoch: 2
[2018-03-25 11:38:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:38:12] Epoch: 3
[2018-03-25 11:38:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 11:38:26] Epoch: 4
[2018-03-25 11:38:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:38:41] Epoch: 5
[2018-03-25 11:38:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:38:55] Epoch: 6
[2018-03-25 11:39:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:39:10] Epoch: 7
[2018-03-25 11:39:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:39:23] Epoch: 8
[2018-03-25 11:39:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:39:38] Epoch: 9
[2018-03-25 11:39:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:39:52] Epoch: 10
[2018-03-25 11:40:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:40:07] Epoch: 11
[2018-03-25 11:40:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:40:21] Epoch: 12
[2018-03-25 11:40:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 11:40:35] Epoch: 13
[2018-03-25 11:40:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:40:49] Epoch: 14
[2018-03-25 11:41:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:41:04] Epoch: 15
[2018-03-25 11:41:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:41:18] Epoch: 16
[2018-03-25 11:41:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:41:33] Epoch: 17
[2018-03-25 11:41:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:41:46] Epoch: 18
[2018-03-25 11:42:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:42:01] Epoch: 19
[2018-03-25 11:42:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:42:15] Epoch: 20
[2018-03-25 11:42:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:42:30] Epoch: 21
[2018-03-25 11:42:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:42:44] Epoch: 22
[2018-03-25 11:42:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:42:59] Epoch: 23
[2018-03-25 11:43:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:43:13] Epoch: 24
[2018-03-25 11:43:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:43:28] Epoch: 25
[2018-03-25 11:43:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:43:42] Epoch: 26
[2018-03-25 11:43:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:43:57] Epoch: 27
[2018-03-25 11:44:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:44:11] Epoch: 28
[2018-03-25 11:44:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:44:26] Epoch: 29
[2018-03-25 11:44:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:44:40] Epoch: 30
[2018-03-25 11:44:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:44:55] Epoch: 31
[2018-03-25 11:45:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:45:09] Epoch: 32
[2018-03-25 11:45:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:45:24] Epoch: 33
[2018-03-25 11:45:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:45:38] Epoch: 34
[2018-03-25 11:45:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:45:53] Epoch: 35
[2018-03-25 11:46:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:46:07] Epoch: 36
[2018-03-25 11:46:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:46:22] Epoch: 37
[2018-03-25 11:46:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:46:36] Epoch: 38
[2018-03-25 11:46:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:46:51] Epoch: 39
[2018-03-25 11:47:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:47:04] Epoch: 40
[2018-03-25 11:47:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:47:19] Epoch: 41
[2018-03-25 11:47:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:47:33] Epoch: 42
[2018-03-25 11:47:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:47:48] Epoch: 43
[2018-03-25 11:48:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:48:02] Epoch: 44
[2018-03-25 11:48:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:48:17] Epoch: 45
[2018-03-25 11:48:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 11:48:31] Epoch: 46
[2018-03-25 11:48:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 11:48:46] Epoch: 47
[2018-03-25 11:49:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 11:49:00] Epoch: 48
[2018-03-25 11:49:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 11:49:14] Epoch: 49
[2018-03-25 11:49:28] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 11:49:28] Training finished.
[2018-03-25 11:49:28] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_114928--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 11:49:29] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 11:50:35] Rankings created.
[2018-03-25 11:50:35] ATP evaluation started...
[2018-03-25 12:17:56]     Number of proved theorems: 115
[2018-03-25 12:17:56]     Percentage of proved theorems: 8.57%
[2018-03-25 12:17:56] Number of all theorems with proof(s): 618
[2018-03-25 12:17:56] Number of all proofs: 1721
[2018-03-25 12:17:56] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 12:17:56] Number of theorems with exactly 2 proof(s): 97
[2018-03-25 12:17:56] Number of theorems with exactly 3 proof(s): 104
[2018-03-25 12:17:56] Number of theorems with exactly 4 proof(s): 65
[2018-03-25 12:17:56] Number of theorems with exactly 5 proof(s): 44
[2018-03-25 12:17:56] Number of theorems with exactly 6 proof(s): 31
[2018-03-25 12:17:56] Number of theorems with exactly 7 proof(s): 13
[2018-03-25 12:17:56] Number of theorems with exactly 8 proof(s): 9
[2018-03-25 12:17:56] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 12:17:56] Number of theorems with exactly 11 proof(s): 2
[2018-03-25 12:17:56] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 12:17:56] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 12:17:56] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 12:17:56] Average number of proofs per theorem: 2.785
[2018-03-25 12:17:56] Average number of premises used in one proof: 7.723
[2018-03-25 12:17:56] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 12:17:56] ITERATION: 24
[2018-03-25 12:17:56] Transforming proofs of 618 theorems to training data...
[2018-03-25 12:17:56]     Number of features used: 5120 / 10241
[2018-03-25 12:17:56]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 12:17:56]     Negatives to positive ratio: 10
[2018-03-25 12:17:56]     Negative mining:
[2018-03-25 12:17:56]         Level of negative mining: all
[2018-03-25 12:17:56]         Part of theorems for negative mining: 0.5
[2018-03-25 12:21:12] Transformation finished.
[2018-03-25 12:21:12] Restoring neural net graph...
[2018-03-25 12:21:12] Training of neural net started...
[2018-03-25 12:21:12] Epoch: 0
[2018-03-25 12:21:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:21:26] Epoch: 1
[2018-03-25 12:21:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:21:39] Epoch: 2
[2018-03-25 12:21:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:21:52] Epoch: 3
[2018-03-25 12:22:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:22:05] Epoch: 4
[2018-03-25 12:22:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:22:18] Epoch: 5
[2018-03-25 12:22:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.92/nan/0.00/nan
[2018-03-25 12:22:31] Epoch: 6
[2018-03-25 12:22:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 12:22:44] Epoch: 7
[2018-03-25 12:22:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:22:57] Epoch: 8
[2018-03-25 12:23:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:23:10] Epoch: 9
[2018-03-25 12:23:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:23:23] Epoch: 10
[2018-03-25 12:23:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:23:36] Epoch: 11
[2018-03-25 12:23:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:23:49] Epoch: 12
[2018-03-25 12:24:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:24:02] Epoch: 13
[2018-03-25 12:24:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 12:24:15] Epoch: 14
[2018-03-25 12:24:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:24:28] Epoch: 15
[2018-03-25 12:24:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:24:41] Epoch: 16
[2018-03-25 12:24:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:24:54] Epoch: 17
[2018-03-25 12:25:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 12:25:07] Epoch: 18
[2018-03-25 12:25:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:25:20] Epoch: 19
[2018-03-25 12:25:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 12:25:32] Epoch: 20
[2018-03-25 12:25:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:25:46] Epoch: 21
[2018-03-25 12:25:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:25:59] Epoch: 22
[2018-03-25 12:26:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:26:11] Epoch: 23
[2018-03-25 12:26:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:26:24] Epoch: 24
[2018-03-25 12:26:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:26:38] Epoch: 25
[2018-03-25 12:26:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:26:50] Epoch: 26
[2018-03-25 12:27:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:27:03] Epoch: 27
[2018-03-25 12:27:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:27:16] Epoch: 28
[2018-03-25 12:27:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:27:30] Epoch: 29
[2018-03-25 12:27:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:27:42] Epoch: 30
[2018-03-25 12:27:55] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 12:27:55] Epoch: 31
[2018-03-25 12:28:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:28:08] Epoch: 32
[2018-03-25 12:28:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 12:28:22] Epoch: 33
[2018-03-25 12:28:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:28:35] Epoch: 34
[2018-03-25 12:28:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:28:47] Epoch: 35
[2018-03-25 12:29:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:29:00] Epoch: 36
[2018-03-25 12:29:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 12:29:14] Epoch: 37
[2018-03-25 12:29:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:29:27] Epoch: 38
[2018-03-25 12:29:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:29:39] Epoch: 39
[2018-03-25 12:29:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:29:52] Epoch: 40
[2018-03-25 12:30:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:30:06] Epoch: 41
[2018-03-25 12:30:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 12:30:19] Epoch: 42
[2018-03-25 12:30:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:30:32] Epoch: 43
[2018-03-25 12:30:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 12:30:45] Epoch: 44
[2018-03-25 12:30:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:30:58] Epoch: 45
[2018-03-25 12:31:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 12:31:11] Epoch: 46
[2018-03-25 12:31:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 12:31:24] Epoch: 47
[2018-03-25 12:31:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 12:31:37] Epoch: 48
[2018-03-25 12:31:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 12:31:51] Epoch: 49
[2018-03-25 12:32:04] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 12:32:04] Training finished.
[2018-03-25 12:32:04] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_123204--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 12:32:04] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 12:33:10] Rankings created.
[2018-03-25 12:33:10] ATP evaluation started...
[2018-03-25 13:06:27]     Number of proved theorems: 148
[2018-03-25 13:06:27]     Percentage of proved theorems: 11.03%
[2018-03-25 13:06:27] Number of all theorems with proof(s): 618
[2018-03-25 13:06:27] Number of all proofs: 1744
[2018-03-25 13:06:27] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 13:06:27] Number of theorems with exactly 2 proof(s): 97
[2018-03-25 13:06:27] Number of theorems with exactly 3 proof(s): 102
[2018-03-25 13:06:27] Number of theorems with exactly 4 proof(s): 61
[2018-03-25 13:06:27] Number of theorems with exactly 5 proof(s): 47
[2018-03-25 13:06:27] Number of theorems with exactly 6 proof(s): 28
[2018-03-25 13:06:27] Number of theorems with exactly 7 proof(s): 17
[2018-03-25 13:06:27] Number of theorems with exactly 8 proof(s): 9
[2018-03-25 13:06:27] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 13:06:27] Number of theorems with exactly 10 proof(s): 2
[2018-03-25 13:06:27] Number of theorems with exactly 11 proof(s): 2
[2018-03-25 13:06:27] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 13:06:27] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 13:06:27] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 13:06:27] Average number of proofs per theorem: 2.822
[2018-03-25 13:06:27] Average number of premises used in one proof: 7.814
[2018-03-25 13:06:27] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 13:06:28] ITERATION: 25
[2018-03-25 13:06:28] Transforming proofs of 618 theorems to training data...
[2018-03-25 13:06:28]     Number of features used: 5120 / 10241
[2018-03-25 13:06:28]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 13:06:28]     Negatives to positive ratio: 10
[2018-03-25 13:06:28]     Negative mining:
[2018-03-25 13:06:28]         Level of negative mining: all
[2018-03-25 13:06:28]         Part of theorems for negative mining: 0.5
[2018-03-25 13:09:39] Transformation finished.
[2018-03-25 13:09:39] Restoring neural net graph...
[2018-03-25 13:09:39] Training of neural net started...
[2018-03-25 13:09:39] Epoch: 0
[2018-03-25 13:09:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:09:54] Epoch: 1
[2018-03-25 13:10:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:10:09] Epoch: 2
[2018-03-25 13:10:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:10:23] Epoch: 3
[2018-03-25 13:10:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:10:38] Epoch: 4
[2018-03-25 13:10:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:10:52] Epoch: 5
[2018-03-25 13:11:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:11:06] Epoch: 6
[2018-03-25 13:11:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:11:20] Epoch: 7
[2018-03-25 13:11:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:11:35] Epoch: 8
[2018-03-25 13:11:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:11:49] Epoch: 9
[2018-03-25 13:12:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 13:12:04] Epoch: 10
[2018-03-25 13:12:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:12:18] Epoch: 11
[2018-03-25 13:12:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:12:33] Epoch: 12
[2018-03-25 13:12:47] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 13:12:47] Epoch: 13
[2018-03-25 13:13:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:13:02] Epoch: 14
[2018-03-25 13:13:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:13:16] Epoch: 15
[2018-03-25 13:13:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:13:31] Epoch: 16
[2018-03-25 13:13:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 13:13:45] Epoch: 17
[2018-03-25 13:14:00] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 13:14:00] Epoch: 18
[2018-03-25 13:14:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:14:14] Epoch: 19
[2018-03-25 13:14:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 13:14:28] Epoch: 20
[2018-03-25 13:14:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:14:42] Epoch: 21
[2018-03-25 13:14:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:14:57] Epoch: 22
[2018-03-25 13:15:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:15:11] Epoch: 23
[2018-03-25 13:15:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:15:26] Epoch: 24
[2018-03-25 13:15:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:15:40] Epoch: 25
[2018-03-25 13:15:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:15:55] Epoch: 26
[2018-03-25 13:16:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:16:09] Epoch: 27
[2018-03-25 13:16:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:16:24] Epoch: 28
[2018-03-25 13:16:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:16:38] Epoch: 29
[2018-03-25 13:16:53] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:16:53] Epoch: 30
[2018-03-25 13:17:07] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:17:07] Epoch: 31
[2018-03-25 13:17:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:17:22] Epoch: 32
[2018-03-25 13:17:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:17:36] Epoch: 33
[2018-03-25 13:17:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:17:51] Epoch: 34
[2018-03-25 13:18:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:18:05] Epoch: 35
[2018-03-25 13:18:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:18:20] Epoch: 36
[2018-03-25 13:18:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:18:34] Epoch: 37
[2018-03-25 13:18:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:18:49] Epoch: 38
[2018-03-25 13:19:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:19:03] Epoch: 39
[2018-03-25 13:19:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:19:17] Epoch: 40
[2018-03-25 13:19:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:19:31] Epoch: 41
[2018-03-25 13:19:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:19:46] Epoch: 42
[2018-03-25 13:20:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:20:00] Epoch: 43
[2018-03-25 13:20:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 13:20:15] Epoch: 44
[2018-03-25 13:20:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:20:29] Epoch: 45
[2018-03-25 13:20:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:20:44] Epoch: 46
[2018-03-25 13:20:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:20:58] Epoch: 47
[2018-03-25 13:21:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:21:13] Epoch: 48
[2018-03-25 13:21:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:21:27] Epoch: 49
[2018-03-25 13:21:42] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 13:21:42] Training finished.
[2018-03-25 13:21:42] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_132142--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 13:21:43] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 13:22:48] Rankings created.
[2018-03-25 13:22:48] ATP evaluation started...
[2018-03-25 13:51:40]     Number of proved theorems: 123
[2018-03-25 13:51:40]     Percentage of proved theorems: 9.17%
[2018-03-25 13:51:40] Number of all theorems with proof(s): 619
[2018-03-25 13:51:40] Number of all proofs: 1754
[2018-03-25 13:51:40] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 13:51:40] Number of theorems with exactly 2 proof(s): 96
[2018-03-25 13:51:40] Number of theorems with exactly 3 proof(s): 101
[2018-03-25 13:51:40] Number of theorems with exactly 4 proof(s): 63
[2018-03-25 13:51:40] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 13:51:40] Number of theorems with exactly 6 proof(s): 27
[2018-03-25 13:51:40] Number of theorems with exactly 7 proof(s): 18
[2018-03-25 13:51:40] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 13:51:40] Number of theorems with exactly 9 proof(s): 7
[2018-03-25 13:51:40] Number of theorems with exactly 10 proof(s): 3
[2018-03-25 13:51:40] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 13:51:40] Number of theorems with exactly 12 proof(s): 3
[2018-03-25 13:51:40] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 13:51:40] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 13:51:40] Average number of proofs per theorem: 2.834
[2018-03-25 13:51:40] Average number of premises used in one proof: 7.842
[2018-03-25 13:51:40] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 13:51:40] ITERATION: 26
[2018-03-25 13:51:40] Transforming proofs of 619 theorems to training data...
[2018-03-25 13:51:40]     Number of features used: 5120 / 10241
[2018-03-25 13:51:40]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 13:51:40]     Negatives to positive ratio: 10
[2018-03-25 13:51:40]     Negative mining:
[2018-03-25 13:51:40]         Level of negative mining: all
[2018-03-25 13:51:40]         Part of theorems for negative mining: 0.5
[2018-03-25 13:54:57] Transformation finished.
[2018-03-25 13:54:57] Restoring neural net graph...
[2018-03-25 13:54:57] Training of neural net started...
[2018-03-25 13:54:57] Epoch: 0
[2018-03-25 13:55:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:55:12] Epoch: 1
[2018-03-25 13:55:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:55:26] Epoch: 2
[2018-03-25 13:55:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 13:55:41] Epoch: 3
[2018-03-25 13:55:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:55:54] Epoch: 4
[2018-03-25 13:56:09] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 13:56:09] Epoch: 5
[2018-03-25 13:56:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:56:22] Epoch: 6
[2018-03-25 13:56:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:56:37] Epoch: 7
[2018-03-25 13:56:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:56:51] Epoch: 8
[2018-03-25 13:57:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:57:05] Epoch: 9
[2018-03-25 13:57:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:57:19] Epoch: 10
[2018-03-25 13:57:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:57:33] Epoch: 11
[2018-03-25 13:57:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:57:47] Epoch: 12
[2018-03-25 13:58:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:58:01] Epoch: 13
[2018-03-25 13:58:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:58:15] Epoch: 14
[2018-03-25 13:58:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:58:30] Epoch: 15
[2018-03-25 13:58:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 13:58:43] Epoch: 16
[2018-03-25 13:58:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:58:58] Epoch: 17
[2018-03-25 13:59:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 13:59:11] Epoch: 18
[2018-03-25 13:59:26] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 13:59:26] Epoch: 19
[2018-03-25 13:59:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 13:59:39] Epoch: 20
[2018-03-25 13:59:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 13:59:54] Epoch: 21
[2018-03-25 14:00:07] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:00:07] Epoch: 22
[2018-03-25 14:00:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:00:22] Epoch: 23
[2018-03-25 14:00:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:00:35] Epoch: 24
[2018-03-25 14:00:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:00:50] Epoch: 25
[2018-03-25 14:01:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:01:04] Epoch: 26
[2018-03-25 14:01:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:01:18] Epoch: 27
[2018-03-25 14:01:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:01:32] Epoch: 28
[2018-03-25 14:01:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:01:46] Epoch: 29
[2018-03-25 14:02:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:02:00] Epoch: 30
[2018-03-25 14:02:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:02:14] Epoch: 31
[2018-03-25 14:02:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:02:27] Epoch: 32
[2018-03-25 14:02:42] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:02:42] Epoch: 33
[2018-03-25 14:02:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:02:55] Epoch: 34
[2018-03-25 14:03:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:03:10] Epoch: 35
[2018-03-25 14:03:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:03:23] Epoch: 36
[2018-03-25 14:03:38] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:03:38] Epoch: 37
[2018-03-25 14:03:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:03:52] Epoch: 38
[2018-03-25 14:04:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:04:06] Epoch: 39
[2018-03-25 14:04:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:04:20] Epoch: 40
[2018-03-25 14:04:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:04:34] Epoch: 41
[2018-03-25 14:04:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:04:48] Epoch: 42
[2018-03-25 14:05:02] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:05:02] Epoch: 43
[2018-03-25 14:05:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:05:16] Epoch: 44
[2018-03-25 14:05:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:05:31] Epoch: 45
[2018-03-25 14:05:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:05:44] Epoch: 46
[2018-03-25 14:05:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:05:59] Epoch: 47
[2018-03-25 14:06:12] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 14:06:12] Epoch: 48
[2018-03-25 14:06:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:06:27] Epoch: 49
[2018-03-25 14:06:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:06:40] Training finished.
[2018-03-25 14:06:40] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_140640--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 14:06:40] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 14:07:46] Rankings created.
[2018-03-25 14:07:46] ATP evaluation started...
[2018-03-25 14:37:42]     Number of proved theorems: 145
[2018-03-25 14:37:42]     Percentage of proved theorems: 10.80%
[2018-03-25 14:37:42] Number of all theorems with proof(s): 619
[2018-03-25 14:37:42] Number of all proofs: 1770
[2018-03-25 14:37:42] Number of theorems with exactly 1 proof(s): 242
[2018-03-25 14:37:42] Number of theorems with exactly 2 proof(s): 96
[2018-03-25 14:37:42] Number of theorems with exactly 3 proof(s): 101
[2018-03-25 14:37:42] Number of theorems with exactly 4 proof(s): 58
[2018-03-25 14:37:42] Number of theorems with exactly 5 proof(s): 48
[2018-03-25 14:37:42] Number of theorems with exactly 6 proof(s): 30
[2018-03-25 14:37:42] Number of theorems with exactly 7 proof(s): 16
[2018-03-25 14:37:42] Number of theorems with exactly 8 proof(s): 12
[2018-03-25 14:37:42] Number of theorems with exactly 9 proof(s): 6
[2018-03-25 14:37:42] Number of theorems with exactly 10 proof(s): 4
[2018-03-25 14:37:42] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 14:37:42] Number of theorems with exactly 13 proof(s): 2
[2018-03-25 14:37:42] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 14:37:42] Number of theorems with exactly 15 proof(s): 1
[2018-03-25 14:37:42] Average number of proofs per theorem: 2.859
[2018-03-25 14:37:42] Average number of premises used in one proof: 7.886
[2018-03-25 14:37:42] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 14:37:42] ITERATION: 27
[2018-03-25 14:37:42] Transforming proofs of 619 theorems to training data...
[2018-03-25 14:37:42]     Number of features used: 5120 / 10241
[2018-03-25 14:37:42]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 14:37:42]     Negatives to positive ratio: 10
[2018-03-25 14:37:42]     Negative mining:
[2018-03-25 14:37:42]         Level of negative mining: all
[2018-03-25 14:37:42]         Part of theorems for negative mining: 0.5
[2018-03-25 14:40:52] Transformation finished.
[2018-03-25 14:40:52] Restoring neural net graph...
[2018-03-25 14:40:52] Training of neural net started...
[2018-03-25 14:40:52] Epoch: 0
[2018-03-25 14:41:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:41:06] Epoch: 1
[2018-03-25 14:41:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:41:20] Epoch: 2
[2018-03-25 14:41:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:41:34] Epoch: 3
[2018-03-25 14:41:48] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:41:48] Epoch: 4
[2018-03-25 14:42:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:42:01] Epoch: 5
[2018-03-25 14:42:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:42:15] Epoch: 6
[2018-03-25 14:42:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:42:28] Epoch: 7
[2018-03-25 14:42:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:42:42] Epoch: 8
[2018-03-25 14:42:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 14:42:56] Epoch: 9
[2018-03-25 14:43:10] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:43:10] Epoch: 10
[2018-03-25 14:43:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:43:23] Epoch: 11
[2018-03-25 14:43:37] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:43:37] Epoch: 12
[2018-03-25 14:43:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:43:51] Epoch: 13
[2018-03-25 14:44:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:44:05] Epoch: 14
[2018-03-25 14:44:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:44:18] Epoch: 15
[2018-03-25 14:44:32] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:44:32] Epoch: 16
[2018-03-25 14:44:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 14:44:45] Epoch: 17
[2018-03-25 14:44:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:44:59] Epoch: 18
[2018-03-25 14:45:13] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:45:13] Epoch: 19
[2018-03-25 14:45:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:45:27] Epoch: 20
[2018-03-25 14:45:40] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:45:40] Epoch: 21
[2018-03-25 14:45:54] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:45:54] Epoch: 22
[2018-03-25 14:46:08] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:46:08] Epoch: 23
[2018-03-25 14:46:22] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:46:22] Epoch: 24
[2018-03-25 14:46:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 14:46:35] Epoch: 25
[2018-03-25 14:46:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:46:49] Epoch: 26
[2018-03-25 14:47:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:47:03] Epoch: 27
[2018-03-25 14:47:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:47:17] Epoch: 28
[2018-03-25 14:47:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:47:31] Epoch: 29
[2018-03-25 14:47:45] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:47:45] Epoch: 30
[2018-03-25 14:47:59] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:47:59] Epoch: 31
[2018-03-25 14:48:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:48:13] Epoch: 32
[2018-03-25 14:48:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:48:27] Epoch: 33
[2018-03-25 14:48:41] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:48:41] Epoch: 34
[2018-03-25 14:48:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:48:55] Epoch: 35
[2018-03-25 14:49:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 14:49:09] Epoch: 36
[2018-03-25 14:49:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:49:23] Epoch: 37
[2018-03-25 14:49:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:49:37] Epoch: 38
[2018-03-25 14:49:51] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:49:51] Epoch: 39
[2018-03-25 14:50:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:50:05] Epoch: 40
[2018-03-25 14:50:19] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:50:19] Epoch: 41
[2018-03-25 14:50:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 14:50:33] Epoch: 42
[2018-03-25 14:50:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:50:46] Epoch: 43
[2018-03-25 14:51:01] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 14:51:01] Epoch: 44
[2018-03-25 14:51:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:51:15] Epoch: 45
[2018-03-25 14:51:29] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 14:51:29] Epoch: 46
[2018-03-25 14:51:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:51:42] Epoch: 47
[2018-03-25 14:51:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 14:51:57] Epoch: 48
[2018-03-25 14:52:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:52:10] Epoch: 49
[2018-03-25 14:52:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 14:52:25] Training finished.
[2018-03-25 14:52:25] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_145225--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 14:52:25] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 14:53:27] Rankings created.
[2018-03-25 14:53:27] ATP evaluation started...
[2018-03-25 15:25:53]     Number of proved theorems: 151
[2018-03-25 15:25:53]     Percentage of proved theorems: 11.25%
[2018-03-25 15:25:53] Number of all theorems with proof(s): 619
[2018-03-25 15:25:53] Number of all proofs: 1783
[2018-03-25 15:25:53] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 15:25:53] Number of theorems with exactly 2 proof(s): 97
[2018-03-25 15:25:53] Number of theorems with exactly 3 proof(s): 101
[2018-03-25 15:25:53] Number of theorems with exactly 4 proof(s): 57
[2018-03-25 15:25:53] Number of theorems with exactly 5 proof(s): 49
[2018-03-25 15:25:53] Number of theorems with exactly 6 proof(s): 28
[2018-03-25 15:25:53] Number of theorems with exactly 7 proof(s): 17
[2018-03-25 15:25:53] Number of theorems with exactly 8 proof(s): 10
[2018-03-25 15:25:53] Number of theorems with exactly 9 proof(s): 7
[2018-03-25 15:25:53] Number of theorems with exactly 10 proof(s): 5
[2018-03-25 15:25:53] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 15:25:53] Number of theorems with exactly 12 proof(s): 1
[2018-03-25 15:25:53] Number of theorems with exactly 13 proof(s): 2
[2018-03-25 15:25:53] Number of theorems with exactly 14 proof(s): 2
[2018-03-25 15:25:53] Number of theorems with exactly 15 proof(s): 1
[2018-03-25 15:25:53] Average number of proofs per theorem: 2.880
[2018-03-25 15:25:53] Average number of premises used in one proof: 7.921
[2018-03-25 15:25:53] Theorems with maximal number of proofs found: ['t61_setfam_1']
[2018-03-25 15:25:53] ITERATION: 28
[2018-03-25 15:25:53] Transforming proofs of 619 theorems to training data...
[2018-03-25 15:25:53]     Number of features used: 5120 / 10241
[2018-03-25 15:25:53]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 15:25:53]     Negatives to positive ratio: 10
[2018-03-25 15:25:53]     Negative mining:
[2018-03-25 15:25:53]         Level of negative mining: all
[2018-03-25 15:25:53]         Part of theorems for negative mining: 0.5
[2018-03-25 15:29:05] Transformation finished.
[2018-03-25 15:29:05] Restoring neural net graph...
[2018-03-25 15:29:06] Training of neural net started...
[2018-03-25 15:29:06] Epoch: 0
[2018-03-25 15:29:20] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:29:20] Epoch: 1
[2018-03-25 15:29:34] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:29:34] Epoch: 2
[2018-03-25 15:29:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 15:29:47] Epoch: 3
[2018-03-25 15:30:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 15:30:00] Epoch: 4
[2018-03-25 15:30:15] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:30:15] Epoch: 5
[2018-03-25 15:30:28] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:30:28] Epoch: 6
[2018-03-25 15:30:42] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 15:30:42] Epoch: 7
[2018-03-25 15:30:55] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:30:55] Epoch: 8
[2018-03-25 15:31:09] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:31:09] Epoch: 9
[2018-03-25 15:31:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 15:31:23] Epoch: 10
[2018-03-25 15:31:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:31:36] Epoch: 11
[2018-03-25 15:31:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:31:50] Epoch: 12
[2018-03-25 15:32:04] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:32:04] Epoch: 13
[2018-03-25 15:32:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 15:32:17] Epoch: 14
[2018-03-25 15:32:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 15:32:30] Epoch: 15
[2018-03-25 15:32:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:32:44] Epoch: 16
[2018-03-25 15:32:58] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:32:58] Epoch: 17
[2018-03-25 15:33:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:33:11] Epoch: 18
[2018-03-25 15:33:25] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:33:25] Epoch: 19
[2018-03-25 15:33:38] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:33:38] Epoch: 20
[2018-03-25 15:33:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:33:52] Epoch: 21
[2018-03-25 15:34:06] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:34:06] Epoch: 22
[2018-03-25 15:34:19] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 15:34:19] Epoch: 23
[2018-03-25 15:34:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:34:33] Epoch: 24
[2018-03-25 15:34:47] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:34:47] Epoch: 25
[2018-03-25 15:35:00] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:35:00] Epoch: 26
[2018-03-25 15:35:14] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:35:14] Epoch: 27
[2018-03-25 15:35:27] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 15:35:27] Epoch: 28
[2018-03-25 15:35:41] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:35:41] Epoch: 29
[2018-03-25 15:35:55] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:35:55] Epoch: 30
[2018-03-25 15:36:08] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:36:08] Epoch: 31
[2018-03-25 15:36:21] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:36:21] Epoch: 32
[2018-03-25 15:36:35] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:36:35] Epoch: 33
[2018-03-25 15:36:49] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:36:49] Epoch: 34
[2018-03-25 15:37:02] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:37:02] Epoch: 35
[2018-03-25 15:37:15] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:37:15] Epoch: 36
[2018-03-25 15:37:29] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 15:37:29] Epoch: 37
[2018-03-25 15:37:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:37:43] Epoch: 38
[2018-03-25 15:37:56] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:37:56] Epoch: 39
[2018-03-25 15:38:09] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:38:09] Epoch: 40
[2018-03-25 15:38:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 15:38:23] Epoch: 41
[2018-03-25 15:38:36] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 15:38:36] Epoch: 42
[2018-03-25 15:38:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 15:38:50] Epoch: 43
[2018-03-25 15:39:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 15:39:03] Epoch: 44
[2018-03-25 15:39:17] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:39:17] Epoch: 45
[2018-03-25 15:39:30] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:39:30] Epoch: 46
[2018-03-25 15:39:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 15:39:44] Epoch: 47
[2018-03-25 15:39:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 15:39:57] Epoch: 48
[2018-03-25 15:40:11] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 15:40:11] Epoch: 49
[2018-03-25 15:40:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 15:40:24] Training finished.
[2018-03-25 15:40:24] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_154024--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 15:40:25] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 15:41:30] Rankings created.
[2018-03-25 15:41:30] ATP evaluation started...
[2018-03-25 16:07:49]     Number of proved theorems: 164
[2018-03-25 16:07:49]     Percentage of proved theorems: 12.22%
[2018-03-25 16:07:49] Number of all theorems with proof(s): 620
[2018-03-25 16:07:49] Number of all proofs: 1812
[2018-03-25 16:07:49] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 16:07:49] Number of theorems with exactly 2 proof(s): 97
[2018-03-25 16:07:49] Number of theorems with exactly 3 proof(s): 101
[2018-03-25 16:07:49] Number of theorems with exactly 4 proof(s): 53
[2018-03-25 16:07:49] Number of theorems with exactly 5 proof(s): 47
[2018-03-25 16:07:49] Number of theorems with exactly 6 proof(s): 29
[2018-03-25 16:07:49] Number of theorems with exactly 7 proof(s): 20
[2018-03-25 16:07:49] Number of theorems with exactly 8 proof(s): 12
[2018-03-25 16:07:49] Number of theorems with exactly 9 proof(s): 7
[2018-03-25 16:07:49] Number of theorems with exactly 10 proof(s): 6
[2018-03-25 16:07:49] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 16:07:49] Number of theorems with exactly 12 proof(s): 1
[2018-03-25 16:07:49] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 16:07:49] Number of theorems with exactly 14 proof(s): 2
[2018-03-25 16:07:49] Number of theorems with exactly 15 proof(s): 2
[2018-03-25 16:07:49] Average number of proofs per theorem: 2.923
[2018-03-25 16:07:49] Average number of premises used in one proof: 7.949
[2018-03-25 16:07:49] Theorems with maximal number of proofs found: ['t61_setfam_1', 't80_xboole_1']
[2018-03-25 16:07:49] ITERATION: 29
[2018-03-25 16:07:49] Transforming proofs of 620 theorems to training data...
[2018-03-25 16:07:49]     Number of features used: 5120 / 10241
[2018-03-25 16:07:49]     Mode of combining theorems and premises to examples: merge_mode=concat
[2018-03-25 16:07:49]     Negatives to positive ratio: 10
[2018-03-25 16:07:49]     Negative mining:
[2018-03-25 16:07:49]         Level of negative mining: all
[2018-03-25 16:07:49]         Part of theorems for negative mining: 0.5
[2018-03-25 16:11:07] Transformation finished.
[2018-03-25 16:11:07] Restoring neural net graph...
[2018-03-25 16:11:07] Training of neural net started...
[2018-03-25 16:11:07] Epoch: 0
[2018-03-25 16:11:20] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 16:11:20] Epoch: 1
[2018-03-25 16:11:33] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:11:33] Epoch: 2
[2018-03-25 16:11:46] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:11:46] Epoch: 3
[2018-03-25 16:11:59] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:11:59] Epoch: 4
[2018-03-25 16:12:13] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:12:13] Epoch: 5
[2018-03-25 16:12:26] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 16:12:26] Epoch: 6
[2018-03-25 16:12:39] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:12:39] Epoch: 7
[2018-03-25 16:12:52] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:12:52] Epoch: 8
[2018-03-25 16:13:05] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:13:05] Epoch: 9
[2018-03-25 16:13:18] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:13:18] Epoch: 10
[2018-03-25 16:13:31] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:13:31] Epoch: 11
[2018-03-25 16:13:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:13:44] Epoch: 12
[2018-03-25 16:13:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:13:57] Epoch: 13
[2018-03-25 16:14:11] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:14:11] Epoch: 14
[2018-03-25 16:14:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:14:24] Epoch: 15
[2018-03-25 16:14:37] Accuracy/Precision/Recall/F1-score on a random training batch:   1.00/nan/nan/nan
[2018-03-25 16:14:37] Epoch: 16
[2018-03-25 16:14:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:14:50] Epoch: 17
[2018-03-25 16:15:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:15:04] Epoch: 18
[2018-03-25 16:15:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:15:17] Epoch: 19
[2018-03-25 16:15:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:15:30] Epoch: 20
[2018-03-25 16:15:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:15:44] Epoch: 21
[2018-03-25 16:15:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 16:15:57] Epoch: 22
[2018-03-25 16:16:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:16:11] Epoch: 23
[2018-03-25 16:16:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:16:24] Epoch: 24
[2018-03-25 16:16:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:16:37] Epoch: 25
[2018-03-25 16:16:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 16:16:50] Epoch: 26
[2018-03-25 16:17:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:17:04] Epoch: 27
[2018-03-25 16:17:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:17:17] Epoch: 28
[2018-03-25 16:17:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:17:30] Epoch: 29
[2018-03-25 16:17:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:17:44] Epoch: 30
[2018-03-25 16:17:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:17:57] Epoch: 31
[2018-03-25 16:18:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:18:10] Epoch: 32
[2018-03-25 16:18:24] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:18:24] Epoch: 33
[2018-03-25 16:18:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:18:37] Epoch: 34
[2018-03-25 16:18:51] Accuracy/Precision/Recall/F1-score on a random training batch:   0.94/nan/0.00/nan
[2018-03-25 16:18:51] Epoch: 35
[2018-03-25 16:19:04] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:19:04] Epoch: 36
[2018-03-25 16:19:17] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:19:17] Epoch: 37
[2018-03-25 16:19:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.96/nan/0.00/nan
[2018-03-25 16:19:30] Epoch: 38
[2018-03-25 16:19:44] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 16:19:44] Epoch: 39
[2018-03-25 16:19:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:19:57] Epoch: 40
[2018-03-25 16:20:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:20:10] Epoch: 41
[2018-03-25 16:20:23] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:20:23] Epoch: 42
[2018-03-25 16:20:37] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:20:37] Epoch: 43
[2018-03-25 16:20:50] Accuracy/Precision/Recall/F1-score on a random training batch:   0.99/nan/0.00/nan
[2018-03-25 16:20:50] Epoch: 44
[2018-03-25 16:21:03] Accuracy/Precision/Recall/F1-score on a random training batch:   0.97/nan/0.00/nan
[2018-03-25 16:21:03] Epoch: 45
[2018-03-25 16:21:16] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:21:16] Epoch: 46
[2018-03-25 16:21:30] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:21:30] Epoch: 47
[2018-03-25 16:21:43] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 16:21:43] Epoch: 48
[2018-03-25 16:21:57] Accuracy/Precision/Recall/F1-score on a random training batch:   0.98/nan/0.00/nan
[2018-03-25 16:21:57] Epoch: 49
[2018-03-25 16:22:10] Accuracy/Precision/Recall/F1-score on a random training batch:   0.95/nan/0.00/nan
[2018-03-25 16:22:10] Training finished.
[2018-03-25 16:22:10] Saving model to file experiments/loop_network_all_h3/model/2018-03-25_162210--e=50,a=relu,hl=100,bs=100,d=0.3,m=network,lr=0.01,nof=10240,l=3
[2018-03-25 16:22:10] Creating rankings of premises from the trained model for 1342 theorems...
[2018-03-25 16:23:16] Rankings created.
[2018-03-25 16:23:16] ATP evaluation started...
[2018-03-25 16:53:16]     Number of proved theorems: 135
[2018-03-25 16:53:16]     Percentage of proved theorems: 10.06%
[2018-03-25 16:53:16] Number of all theorems with proof(s): 620
[2018-03-25 16:53:16] Number of all proofs: 1825
[2018-03-25 16:53:16] Number of theorems with exactly 1 proof(s): 241
[2018-03-25 16:53:16] Number of theorems with exactly 2 proof(s): 96
[2018-03-25 16:53:16] Number of theorems with exactly 3 proof(s): 101
[2018-03-25 16:53:16] Number of theorems with exactly 4 proof(s): 53
[2018-03-25 16:53:16] Number of theorems with exactly 5 proof(s): 46
[2018-03-25 16:53:16] Number of theorems with exactly 6 proof(s): 28
[2018-03-25 16:53:16] Number of theorems with exactly 7 proof(s): 22
[2018-03-25 16:53:16] Number of theorems with exactly 8 proof(s): 12
[2018-03-25 16:53:16] Number of theorems with exactly 9 proof(s): 8
[2018-03-25 16:53:16] Number of theorems with exactly 10 proof(s): 5
[2018-03-25 16:53:16] Number of theorems with exactly 11 proof(s): 1
[2018-03-25 16:53:16] Number of theorems with exactly 12 proof(s): 2
[2018-03-25 16:53:16] Number of theorems with exactly 13 proof(s): 1
[2018-03-25 16:53:16] Number of theorems with exactly 14 proof(s): 1
[2018-03-25 16:53:16] Number of theorems with exactly 15 proof(s): 3
[2018-03-25 16:53:16] Average number of proofs per theorem: 2.944
[2018-03-25 16:53:16] Average number of premises used in one proof: 7.963
[2018-03-25 16:53:16] Theorems with maximal number of proofs found: ['t18_zfmisc_1', 't61_setfam_1', 't80_xboole_1']
